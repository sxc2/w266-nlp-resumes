{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Data Parsing\n",
    "#### Resumes (300MB)\n",
    "\n",
    "\n",
    "### Processes HTML Resumes into Training Sets\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "### Setup\n",
    "\n",
    "Let's import the data from an downloaded source.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries\n",
    "import re\n",
    "import string\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, json\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "\n",
    "# NLTK library for stop word removal\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from xml.dom import minidom\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json = 'data/'\n",
    "raw_xml = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50101\n"
     ]
    }
   ],
   "source": [
    "# parse an xml file by name\n",
    "tree = minidom.parse(path_to_json + 'indeed_com-job_deduped_n_merged_20170315_201357376193103.xml')  \n",
    "items = tree.getElementsByTagName('raw_html')\n",
    "\n",
    "for item in items:\n",
    "    raw_xml.append(item.firstChild.data)\n",
    "\n",
    "print(len(raw_xml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"resume_body\" class=\"vcard single_form-content\">\n",
      "<div id=\"basic_info_row\" class=\"last basicInfo-content\"><div id=\"basic_info_cell\" class=\"data_display\">\n",
      "<h1 id=\"resume-contact\" class=\"fn \" itemprop=\"name\">Electrical Controls Engineer</h1>\n",
      "<h2 id=\"headline\" itemprop=\"jobTitle\">Electrical &amp; Controls Engineer</h2>\n",
      "<div id=\"contact_info_container\">\n",
      "<div class=\"adr\" itemprop=\"address\" itemscope itemtype=\"http://schema.org/PostalAddress\"><p id=\"headline_location\" class=\"locality\" itemprop=\"addressLocality\">Phillipsburg, NJ</p></div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "</div>\n",
      "<p id=\"res_summary\" class=\"summary\">To secure a Sr. Electrical &amp; Controls position</p>\n",
      "<p id=\"employment_eligibility\">Authorized to work in the US for any employer</p>\n",
      "</div></div>\n",
      "<div class=\"section-item workExperience-content\">\n",
      "<div><div class=\"section_title\"><h2>Work Experience</h2></div></div>\n",
      "<div id=\"work-experience-items\" class=\"items-container\">\n",
      "<div id=\"workExperience-EeVtAljMsUOBTllI6yVEOA\" class=\"work-experience-section \"><div class=\"data_display\">\n",
      "<p class=\"work_title title\">Electrical Controls Engineer</p>\n",
      "<div class=\"work_company\" itemprop=\"worksFor\" itemscope itemtype=\"http://schema.org/Organization\">\n",
      "<span class=\"bold\" itemprop=\"name\">NRG Energy</span> <div class=\"separator-hyphen\">-</div> <div class=\"inline-block\" itemprop=\"address\" itemscope itemtype=\"http://schema.org/PostalAddress\"><span itemprop=\"addressLocality\">Portland, PA</span></div>\n",
      "</div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "<p class=\"work_dates\">October 2011 to Present</p>\n",
      "<p class=\"work_description\">Accountable for maintaining and troubleshooting all electrical and plant controls for steam and gas turbine units. Comply with company safety and OSHA requirements. Direct and assist Electrical &amp; Instrumentation technicians. Manage electrical and controls projects, coordinate/oversee vendors, interface with operations and mechanical maintenance departments, Plant IT representative.  Designed and implemented plant wide critical alarm system to reduce operational errors. Plant NERC administrator, responsible for complying with NERC requirements; evaluate critical assets and critical cyber assets</p>\n",
      "</div></div>\n",
      "<div id=\"workExperience-EeVtAljM2FSBTllI6yVEOA\" class=\"work-experience-section \"><div class=\"data_display\">\n",
      "<p class=\"work_title title\">Electrical Engineer</p>\n",
      "<div class=\"work_company\">\n",
      "<span class=\"bold\">Applied Water Management Group/American Water</span> <div class=\"separator-hyphen\">-</div> <div class=\"inline-block\"><span>Hillsborough, NJ</span></div>\n",
      "</div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "<p class=\"work_dates\">August 2010 to October 2011</p>\n",
      "<p class=\"work_description\">Design and prepare one-line diagrams, power and HVAC plans, specifications for waste water/water Treatment systems, conduct on-site inspections of projects under construction, prepare  as-built drawings and documentation of completed construction, Provide electrical power &amp; SCCR calculations, evaluate shop drawings for compliance to specifications, communicate with electrical subcontractor during construction and perform start up testing and troubleshooting. PLC and HMI programming.</p>\n",
      "</div></div>\n",
      "<div id=\"workExperience-EeVtAljM2FWBTllI6yVEOA\" class=\"work-experience-section \"><div class=\"data_display\">\n",
      "<p class=\"work_title title\">Electrical Project Engineer</p>\n",
      "<div class=\"work_company\">\n",
      "<span class=\"bold\">ABEC, Inc</span> <div class=\"separator-hyphen\">-</div> <div class=\"inline-block\"><span>Bethlehem, PA</span></div>\n",
      "</div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "<p class=\"work_dates\">March 2009 to August 2010</p>\n",
      "<p class=\"work_description\">Design, prepare and review AutoCad electrical packages for bioreactors, fermenters and CIP skids for use in the pharmaceutical industry; electrical packages include schematics, control panel layouts and conduit schedule; Developed and implemented test plans for Factory Acceptance Tests (FATs), data sheets and instrument lists; familiar with NEMA, NEC, NFPA 496, UL508 and SCCR</p>\n",
      "</div></div>\n",
      "<div id=\"workExperience-EeVtAljM2FaBTllI6yVEOA\" class=\"work-experience-section \"><div class=\"data_display\">\n",
      "<p class=\"work_title title\">Lead Design Engineer</p>\n",
      "<div class=\"work_company\">\n",
      "<span class=\"bold\">FL Smidth</span> <div class=\"separator-hyphen\">-</div> <div class=\"inline-block\"><span>Bethlehem, PA</span></div>\n",
      "</div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "<p class=\"work_dates\">June 2008 to January 2009</p>\n",
      "</div></div>\n",
      "<div id=\"workExperience-EeVtAljM2FiBTllI6yVEOA\" class=\"work-experience-section last\"><div class=\"data_display\">\n",
      "<p class=\"work_title title\">Sr. Instrumentation &amp; Controls Engineer</p>\n",
      "<div class=\"work_company\">\n",
      "<span class=\"bold\">Graver Water Systems, Inc</span> <div class=\"separator-hyphen\">-</div> <div class=\"inline-block\"><span>Cranford, NJ</span></div>\n",
      "</div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "<p class=\"work_dates\">March 1988 to June 1994</p>\n",
      "<p class=\"work_description\">Designed control systems for water &amp; wastewater treatment equipment; Involved from concept to factory acceptance test; Developed new CADD system. Additional responsibilities include project management and control system integration.  This includes writing specifications of instrumentation equipment, developing wiring diagrams, SAMA and logic and P&amp;I diagrams, control panel layouts, programming PLCs and HMI/SCADA systems.  Software development includes ladder logic, custom database &amp; HMI development.</p>\n",
      "</div></div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"section-item education-content\">\n",
      "<div><div class=\"section_title\"><h2>Education</h2></div></div>\n",
      "<div id=\"education-items\" class=\"items-container\"><div id=\"education-EeVtAljM2FqBTllI6yVEOA\" class=\"education-section last\"><div class=\"data_display\" itemprop=\"alumniOf\" itemscope itemtype=\"http://schema.org/EducationalOrganization\">\n",
      "<p class=\"edu_title\">Bachelor's in Electrical Engineer</p>\n",
      "<div class=\"edu_school\">\n",
      "<span class=\"bold\" itemprop=\"name\">Gannon University</span> <div class=\"separator-hyphen\">-</div> <div class=\"inline-block\" itemprop=\"address\" itemscope itemtype=\"http://schema.org/PostalAddress\"><span itemprop=\"addressLocality\">Erie, PA</span></div>\n",
      "</div>\n",
      "</div></div></div>\n",
      "</div>\n",
      "<div class=\"section-item skills-content\">\n",
      "<div><div class=\"section_title\"><h2>Skills</h2></div></div>\n",
      "<div id=\"skills-items\" class=\"items-container\"><div class=\"data_display\"><div class=\"skill-container resume-element\">\n",
      "<span class=\"skill-text\">Microsoft Office Suite (10+ years)</span>, <span class=\"skill-text\">PLC programming (10+ years)</span>, <span class=\"skill-text\">Autocad (10+ years)</span>, <span class=\"skill-text\">Project Management (5 years)</span>, <span class=\"skill-text\">Detail Oriented (10+ years)</span>, <span class=\"skill-text\">Sap (5 years)</span>, <span class=\"skill-text\">Sharepoint (5 years)</span>, <span class=\"skill-text\">Training (5 years)</span>\n",
      "</div></div></div>\n",
      "</div>\n",
      "<div class=\"section-item certification-content\">\n",
      "<div><div class=\"section_title\"><h2>Certifications/Licenses</h2></div></div>\n",
      "<div id=\"certification-items\" class=\"items-container\"><div id=\"certification-EeVtAmuGPgqBTllI6yVEOA\" class=\"certification-section last\"><div class=\"data_display\"><p class=\"certification_title\">PE Licencse</p></div></div></div>\n",
      "</div>\n",
      "</div>\n",
      "<div id=\"resume_body\" class=\"vcard single_form-content\">\n",
      "<div id=\"basic_info_row\" class=\"last basicInfo-content\"><div id=\"basic_info_cell\" class=\"data_display\">\n",
      "<h1 id=\"resume-contact\" class=\"fn \" itemprop=\"name\">Colgate Oral Health Advisor</h1>\n",
      "<div id=\"contact_info_container\">\n",
      "<div class=\"adr\" itemprop=\"address\" itemscope itemtype=\"http://schema.org/PostalAddress\"><p id=\"headline_location\" class=\"locality\" itemprop=\"addressLocality\">Enid, OK</p></div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "</div>\n",
      "<p id=\"res_summary\" class=\"summary\">To obtain a position with a dental practice as a Registered Dental Hygienist.</p>\n",
      "</div></div>\n",
      "<div class=\"section-item workExperience-content\">\n",
      "<div><div class=\"section_title\"><h2>Work Experience</h2></div></div>\n",
      "<div id=\"work-experience-items\" class=\"items-container\">\n",
      "<div id=\"workExperience-EebJS-t1bCSgf1lI6yVEOA\" class=\"work-experience-section \"><div class=\"data_display\">\n",
      "<p class=\"work_title title\">Colgate Oral Health Advisor</p>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "<p class=\"work_dates\">March 2010 to Present</p>\n",
      "</div></div>\n",
      "<div id=\"workExperience-EebJS-t1kzWgf1lI6yVEOA\" class=\"work-experience-section \"><div class=\"data_display\">\n",
      "<div class=\"work_company\" itemprop=\"worksFor\" itemscope itemtype=\"http://schema.org/Organization\"><span class=\"bold\" itemprop=\"name\">American Dental Education Association</span></div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "<p class=\"work_dates\">August 2007 to Present</p>\n",
      "<p class=\"work_description\">National Honor Society                                                 August 2007-May 2009</p>\n",
      "</div></div>\n",
      "<div id=\"workExperience-EebJS-t1kzigf1lI6yVEOA\" class=\"work-experience-section \"><div class=\"data_display\">\n",
      "<div class=\"work_company\">\n",
      "<span class=\"bold\">American Dental Education Association</span> <div class=\"separator-hyphen\">-</div> <div class=\"inline-block\"><span>Dover, DE</span></div>\n",
      "</div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "<p class=\"work_dates\">September 2012 to July 2015</p>\n",
      "<p class=\"work_description\">Mondays-Fridays</p>\n",
      "</div></div>\n",
      "<div id=\"workExperience-EebJS-t1kzegf1lI6yVEOA\" class=\"work-experience-section \"><div class=\"data_display\">\n",
      "<div class=\"work_company\"><span class=\"bold\">American Dental Education Association</span></div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "<p class=\"work_dates\">May 2014 to June 2014</p>\n",
      "<p class=\"work_description\">• DSDS Give Kids a Smile                                                February 2013 <br>• 2nd grade OHI at Tinker Elementary                                    March 2012 <br>• Oklahoma Mission of Mercy                                             February 2010</p>\n",
      "</div></div>\n",
      "<div id=\"workExperience-EebJS-t1kzqgf1lI6yVEOA\" class=\"work-experience-section \"><div class=\"data_display\">\n",
      "<div class=\"work_company\">\n",
      "<span class=\"bold\">American Dental Education Association</span> <div class=\"separator-hyphen\">-</div> <div class=\"inline-block\"><span>Edmond, OK</span></div>\n",
      "</div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "<p class=\"work_dates\">June 2009 to July 2012</p>\n",
      "<p class=\"work_description\">Mondays-Thursdays</p>\n",
      "</div></div>\n",
      "<div id=\"workExperience-EebJS-t1kzmgf1lI6yVEOA\" class=\"work-experience-section \"><div class=\"data_display\">\n",
      "<div class=\"work_company\"><span class=\"bold\">American Dental Education Association</span></div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "<p class=\"work_dates\">April 2012 to May 2012</p>\n",
      "</div></div>\n",
      "<div id=\"workExperience-EebJS-t1kzagf1lI6yVEOA\" class=\"work-experience-section last\"><div class=\"data_display\">\n",
      "<p class=\"work_title title\">Clinical Teaching Assistant</p>\n",
      "<div class=\"work_company\"><span class=\"bold\">American Dental Education Association</span></div>\n",
      "<div class=\"separator-hyphen\">-</div>\n",
      "<p class=\"work_dates\">August 2008 to May 2009</p>\n",
      "<p class=\"work_description\">COMMUNITY ACTIVITY:</p>\n",
      "</div></div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"section-item education-content\">\n",
      "<div><div class=\"section_title\"><h2>Education</h2></div></div>\n",
      "<div id=\"education-items\" class=\"items-container\"><div id=\"education-EebJS-t1kzygf1lI6yVEOA\" class=\"education-section last\"><div class=\"data_display\" itemprop=\"alumniOf\" itemscope itemtype=\"http://schema.org/EducationalOrganization\">\n",
      "<p class=\"edu_title\">Bachelor of Science in Dental Hygiene</p>\n",
      "<div class=\"edu_school\"><span class=\"bold\" itemprop=\"name\">University of Oklahoma Health Science Center</span></div>\n",
      "<p class=\"edu_dates\">May 2009</p>\n",
      "</div></div></div>\n",
      "</div>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(raw_xml[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"summary\" id=\"res_summary\">To secure a Sr. Electrical &amp; Controls position</p>]\n",
      "[<p class=\"summary\" id=\"res_summary\">To obtain a position with a dental practice as a Registered Dental Hygienist.</p>]\n",
      "[<p class=\"summary\" id=\"res_summary\">To secure a position and contribute to your well-established company's success through the efficient use of my previous experience and skills.</p>]\n",
      "[<p class=\"summary\" id=\"res_summary\">Edit Job Categories: Customer Service (14 Years experience) Total years experience: 14 Years Company Information Company Name:</p>]\n",
      "[<p class=\"summary\" id=\"res_summary\">To be employed by a progressive organization that presents the opportunity to function in all capacities of <br/>engineering, manufacturing, installation, and customer service in the paper, metals, food, marine, ship building, or <br/>pollution control industries.</p>]\n",
      "[<p class=\"summary\" id=\"res_summary\">Self motivated worker with extensive experience in construction &amp; masonry field.Core skills include: Maintenance,operation &amp; control , &amp; repairing. Handle Tasks with accuracy &amp; efficiency very flexible &amp; can adapt to changing work environment.</p>]\n",
      "[<p class=\"summary\" id=\"res_summary\">Detail-orientated industrial construction warehouse worker with 9+ years' experience. Duties included, but were not limited to, off-loading, inspection, inventory, storage, and distribution of all materials on various industrial construction sites while maintaining communication with field engineers and purchasing agents.</p>]\n",
      "[<p class=\"summary\" id=\"res_summary\">5 years military Experiance <br/>2 year military leadership exoeriance <br/>2 year supervisor experiance <br/>Bilingual <br/>Computer Skills</p>]\n",
      "[<p class=\"summary\" id=\"res_summary\">Customer Service Professional with experience in Administrative Support, Sales, and Training and Development.  Seeking a position in a fast paced, high energy environment that requires keen abilities in customer service, communication and leadership. Proficient in Microsoft Programs.</p>]\n",
      "[<p class=\"summary\" id=\"res_summary\">To secure a full-time position in the health care industry that will utilize my knowledge and experience.</p>]\n",
      "[<p class=\"summary\" id=\"res_summary\">To obtain a position that allows me to use my customer service skills and banking experience.</p>]\n",
      "[<p class=\"summary\" id=\"res_summary\">Shift Manager Marlin Tx</p>]\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    soup = BS(raw_xml[i], \"lxml\")\n",
    "    summary = soup.findAll(\"p\", {\"id\": \"res_summary\"})\n",
    "    if (summary):\n",
    "        print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = {}\n",
    "universities = {}\n",
    "certifications = {}\n",
    "skills_lump = []\n",
    "raw_xml = []\n",
    "\n",
    "number_resumes = 10\n",
    "\n",
    "def findWorkTitlesCompanies(item):\n",
    "    job_title_name = \"\"\n",
    "    if (item.find('p')):\n",
    "        paragraph = item.p\n",
    "        if (paragraph.get('class') and 'work_title' in paragraph.get('class')):\n",
    "            job_title_name = paragraph.string\n",
    "            workCompanies = item.findAll(\"div\", {\"class\": \"work_company\"})\n",
    "            for comp in workCompanies:\n",
    "                if (comp.find('span') and comp.find('span').get('class') and 'bold' in comp.find('span').get('class')):\n",
    "                    company_name = comp.find(\"span\", {\"class\": \"bold\"}).string\n",
    "                    if (not (company_name in companies)):\n",
    "                        companies[company_name] = []\n",
    "                    companies[company_name].append(job_title_name)\n",
    "                        \n",
    "# prune out high schools          \n",
    "def findEducation(item):\n",
    "    degree_name = \"\"\n",
    "    if (item.find('p')):\n",
    "        paragraph = item.p\n",
    "        if (paragraph.get('class') and 'edu_title' in paragraph.get('class')):\n",
    "            degree_name = paragraph.string\n",
    "            university = item.findAll(\"div\", {\"class\": \"edu_school\"})\n",
    "            for comp in university:\n",
    "                if (comp.find('span') and comp.find('span').get('class') and 'bold' in comp.find('span').get('class')):\n",
    "                    university_name = comp.find(\"span\", {\"class\": \"bold\"}).string\n",
    "                    if (university_name and 'high school' not in university_name.lower()):\n",
    "                        if (not (university_name in universities)):\n",
    "                            universities[university_name] = []\n",
    "                        universities[university_name].append(degree_name)\n",
    "                        \n",
    "\n",
    "def findCertification(item):\n",
    "    degree_name = \"\"\n",
    "    if (item.find('p')):\n",
    "        paragraph = item.p\n",
    "        if (paragraph.get('class') and 'certification_title' in paragraph.get('class')):\n",
    "            cert_name = paragraph.string\n",
    "            if (not (cert_name in certifications)):\n",
    "                certifications[cert_name] = 0\n",
    "            certifications[cert_name] += 1\n",
    "\n",
    "def findSkills(item):\n",
    "    skills = \"\"\n",
    "    if (item.find('p')):\n",
    "        paragraph = item.p\n",
    "        if (not paragraph.get('class') and paragraph.string != None):\n",
    "            return paragraph.string + \" \"        \n",
    "    return \"\"\n",
    "            \n",
    "    \n",
    "def writeToFile(name_, data_):\n",
    "    with open(name_ + '.json', 'w') as outfile:\n",
    "        json.dump(data_, outfile)\n",
    "\n",
    "def read_raw_xml_and_push():\n",
    "    global raw_xml\n",
    "    print('Starting processing: ' + str(len(raw_xml)) + \" resumes.\")\n",
    "    for i in range(len(raw_xml)):\n",
    "        soup = BS(raw_xml[i], \"lxml\")\n",
    "        data_display = soup.findAll(\"div\", {\"class\": \"data_display\"})\n",
    "        for item in data_display:\n",
    "            findWorkTitlesCompanies(item)\n",
    "            findEducation(item)\n",
    "            findCertification(item)\n",
    "            skills_lump.append(findSkills(item))\n",
    "            \n",
    "        if ((i % 500) == 0):\n",
    "            print(\"Processed: \" + str(i) + \" resumes.\")\n",
    "\n",
    "def read_raw_xml_and_push_test():    \n",
    "    for i in range(number_resumes):\n",
    "        soup = BS(raw_xml[i], \"lxml\")\n",
    "        data_display = soup.findAll(\"div\", {\"class\": \"data_display\"})\n",
    "        for item in data_display:\n",
    "            findWorkTitlesCompanies(item)\n",
    "            findEducation(item)\n",
    "            findCertification(item)\n",
    "            skills_lump = skills_lump + findSkills(item)\n",
    "\n",
    "def read_next_xml(filename):\n",
    "    global raw_xml\n",
    "    raw_xml = []\n",
    "    tree = minidom.parse(path_to_json + filename)  \n",
    "    items = tree.getElementsByTagName('raw_html')\n",
    "    for item in items:\n",
    "        raw_xml.append(item.firstChild.data)\n",
    "\n",
    "    print(\"Read: \" + filename + \" with elements:\"+ str(len(raw_xml)))\n",
    "\n",
    "#print(companies)\n",
    "#print(universities)\n",
    "#print(certifications)\n",
    "#print(skills_lump)\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: indeed_com-job_deduped_n_merged_20170315_203311012815474.xml with elements:50154\n",
      "Starting processing: 50154 resumes.\n",
      "Processed: 0 resumes.\n",
      "Processed: 500 resumes.\n",
      "Processed: 1000 resumes.\n",
      "Processed: 1500 resumes.\n",
      "Processed: 2000 resumes.\n",
      "Processed: 2500 resumes.\n",
      "Processed: 3000 resumes.\n",
      "Processed: 3500 resumes.\n",
      "Processed: 4000 resumes.\n",
      "Processed: 4500 resumes.\n",
      "Processed: 5000 resumes.\n",
      "Processed: 5500 resumes.\n",
      "Processed: 6000 resumes.\n",
      "Processed: 6500 resumes.\n",
      "Processed: 7000 resumes.\n",
      "Processed: 7500 resumes.\n",
      "Processed: 8000 resumes.\n",
      "Processed: 8500 resumes.\n",
      "Processed: 9000 resumes.\n",
      "Processed: 9500 resumes.\n",
      "Processed: 10000 resumes.\n",
      "Processed: 10500 resumes.\n",
      "Processed: 11000 resumes.\n",
      "Processed: 11500 resumes.\n",
      "Processed: 12000 resumes.\n",
      "Processed: 12500 resumes.\n",
      "Processed: 13000 resumes.\n",
      "Processed: 13500 resumes.\n",
      "Processed: 14000 resumes.\n",
      "Processed: 14500 resumes.\n",
      "Processed: 15000 resumes.\n",
      "Processed: 15500 resumes.\n",
      "Processed: 16000 resumes.\n",
      "Processed: 16500 resumes.\n",
      "Processed: 17000 resumes.\n",
      "Processed: 17500 resumes.\n",
      "Processed: 18000 resumes.\n",
      "Processed: 18500 resumes.\n",
      "Processed: 19000 resumes.\n",
      "Processed: 19500 resumes.\n",
      "Processed: 20000 resumes.\n",
      "Processed: 20500 resumes.\n",
      "Processed: 21000 resumes.\n",
      "Processed: 21500 resumes.\n",
      "Processed: 22000 resumes.\n",
      "Processed: 22500 resumes.\n",
      "Processed: 23000 resumes.\n",
      "Processed: 23500 resumes.\n",
      "Processed: 24000 resumes.\n",
      "Processed: 24500 resumes.\n",
      "Processed: 25000 resumes.\n",
      "Processed: 25500 resumes.\n",
      "Processed: 26000 resumes.\n",
      "Processed: 26500 resumes.\n",
      "Processed: 27000 resumes.\n",
      "Processed: 27500 resumes.\n",
      "Processed: 28000 resumes.\n",
      "Processed: 28500 resumes.\n",
      "Processed: 29000 resumes.\n",
      "Processed: 29500 resumes.\n",
      "Processed: 30000 resumes.\n",
      "Processed: 30500 resumes.\n",
      "Processed: 31000 resumes.\n",
      "Processed: 31500 resumes.\n",
      "Processed: 32000 resumes.\n",
      "Processed: 32500 resumes.\n",
      "Processed: 33000 resumes.\n",
      "Processed: 33500 resumes.\n",
      "Processed: 34000 resumes.\n",
      "Processed: 34500 resumes.\n",
      "Processed: 35000 resumes.\n",
      "Processed: 35500 resumes.\n",
      "Processed: 36000 resumes.\n",
      "Processed: 36500 resumes.\n",
      "Processed: 37000 resumes.\n",
      "Processed: 37500 resumes.\n",
      "Processed: 38000 resumes.\n",
      "Processed: 38500 resumes.\n",
      "Processed: 39000 resumes.\n",
      "Processed: 39500 resumes.\n",
      "Processed: 40000 resumes.\n",
      "Processed: 40500 resumes.\n",
      "Processed: 41000 resumes.\n",
      "Processed: 41500 resumes.\n",
      "Processed: 42000 resumes.\n",
      "Processed: 42500 resumes.\n",
      "Processed: 43000 resumes.\n",
      "Processed: 43500 resumes.\n",
      "Processed: 44000 resumes.\n",
      "Processed: 44500 resumes.\n",
      "Processed: 45000 resumes.\n",
      "Processed: 45500 resumes.\n",
      "Processed: 46000 resumes.\n",
      "Processed: 46500 resumes.\n",
      "Processed: 47000 resumes.\n",
      "Processed: 47500 resumes.\n",
      "Processed: 48000 resumes.\n",
      "Processed: 48500 resumes.\n",
      "Processed: 49000 resumes.\n",
      "Processed: 49500 resumes.\n",
      "Processed: 50000 resumes.\n",
      "Read: indeed_com-job_deduped_n_merged_20170315_201906034655968.xml with elements:50227\n",
      "Starting processing: 50227 resumes.\n",
      "Processed: 0 resumes.\n",
      "Processed: 500 resumes.\n",
      "Processed: 1000 resumes.\n",
      "Processed: 1500 resumes.\n",
      "Processed: 2000 resumes.\n",
      "Processed: 2500 resumes.\n",
      "Processed: 3000 resumes.\n",
      "Processed: 3500 resumes.\n",
      "Processed: 4000 resumes.\n",
      "Processed: 4500 resumes.\n",
      "Processed: 5000 resumes.\n",
      "Processed: 5500 resumes.\n",
      "Processed: 6000 resumes.\n",
      "Processed: 6500 resumes.\n",
      "Processed: 7000 resumes.\n",
      "Processed: 7500 resumes.\n",
      "Processed: 8000 resumes.\n",
      "Processed: 8500 resumes.\n",
      "Processed: 9000 resumes.\n",
      "Processed: 9500 resumes.\n",
      "Processed: 10000 resumes.\n",
      "Processed: 10500 resumes.\n",
      "Processed: 11000 resumes.\n",
      "Processed: 11500 resumes.\n",
      "Processed: 12000 resumes.\n",
      "Processed: 12500 resumes.\n",
      "Processed: 13000 resumes.\n",
      "Processed: 13500 resumes.\n",
      "Processed: 14000 resumes.\n",
      "Processed: 14500 resumes.\n",
      "Processed: 15000 resumes.\n",
      "Processed: 15500 resumes.\n",
      "Processed: 16000 resumes.\n",
      "Processed: 16500 resumes.\n",
      "Processed: 17000 resumes.\n",
      "Processed: 17500 resumes.\n",
      "Processed: 18000 resumes.\n",
      "Processed: 18500 resumes.\n",
      "Processed: 19000 resumes.\n",
      "Processed: 19500 resumes.\n",
      "Processed: 20000 resumes.\n",
      "Processed: 20500 resumes.\n",
      "Processed: 21000 resumes.\n",
      "Processed: 21500 resumes.\n",
      "Processed: 22000 resumes.\n",
      "Processed: 22500 resumes.\n",
      "Processed: 23000 resumes.\n",
      "Processed: 23500 resumes.\n",
      "Processed: 24000 resumes.\n",
      "Processed: 24500 resumes.\n",
      "Processed: 25000 resumes.\n",
      "Processed: 25500 resumes.\n",
      "Processed: 26000 resumes.\n",
      "Processed: 26500 resumes.\n",
      "Processed: 27000 resumes.\n",
      "Processed: 27500 resumes.\n",
      "Processed: 28000 resumes.\n",
      "Processed: 28500 resumes.\n",
      "Processed: 29000 resumes.\n",
      "Processed: 29500 resumes.\n",
      "Processed: 30000 resumes.\n",
      "Processed: 30500 resumes.\n",
      "Processed: 31000 resumes.\n",
      "Processed: 31500 resumes.\n",
      "Processed: 32000 resumes.\n",
      "Processed: 32500 resumes.\n",
      "Processed: 33000 resumes.\n",
      "Processed: 33500 resumes.\n",
      "Processed: 34000 resumes.\n",
      "Processed: 34500 resumes.\n",
      "Processed: 35000 resumes.\n",
      "Processed: 35500 resumes.\n",
      "Processed: 36000 resumes.\n",
      "Processed: 36500 resumes.\n",
      "Processed: 37000 resumes.\n",
      "Processed: 37500 resumes.\n",
      "Processed: 38000 resumes.\n",
      "Processed: 38500 resumes.\n",
      "Processed: 39000 resumes.\n",
      "Processed: 39500 resumes.\n",
      "Processed: 40000 resumes.\n",
      "Processed: 40500 resumes.\n",
      "Processed: 41000 resumes.\n",
      "Processed: 41500 resumes.\n",
      "Processed: 42000 resumes.\n",
      "Processed: 42500 resumes.\n",
      "Processed: 43000 resumes.\n",
      "Processed: 43500 resumes.\n",
      "Processed: 44000 resumes.\n",
      "Processed: 44500 resumes.\n",
      "Processed: 45000 resumes.\n",
      "Processed: 45500 resumes.\n",
      "Processed: 46000 resumes.\n",
      "Processed: 46500 resumes.\n",
      "Processed: 47000 resumes.\n",
      "Processed: 47500 resumes.\n",
      "Processed: 48000 resumes.\n",
      "Processed: 48500 resumes.\n",
      "Processed: 49000 resumes.\n",
      "Processed: 49500 resumes.\n",
      "Processed: 50000 resumes.\n",
      "Read: indeed_com-job_deduped_n_merged_20170315_203459248507509.xml with elements:50793\n",
      "Starting processing: 50793 resumes.\n",
      "Processed: 0 resumes.\n",
      "Processed: 500 resumes.\n",
      "Processed: 1000 resumes.\n",
      "Processed: 1500 resumes.\n",
      "Processed: 2000 resumes.\n",
      "Processed: 2500 resumes.\n",
      "Processed: 3000 resumes.\n",
      "Processed: 3500 resumes.\n",
      "Processed: 4000 resumes.\n",
      "Processed: 4500 resumes.\n",
      "Processed: 5000 resumes.\n",
      "Processed: 5500 resumes.\n",
      "Processed: 6000 resumes.\n",
      "Processed: 6500 resumes.\n",
      "Processed: 7000 resumes.\n",
      "Processed: 7500 resumes.\n",
      "Processed: 8000 resumes.\n",
      "Processed: 8500 resumes.\n",
      "Processed: 9000 resumes.\n",
      "Processed: 9500 resumes.\n",
      "Processed: 10000 resumes.\n",
      "Processed: 10500 resumes.\n",
      "Processed: 11000 resumes.\n",
      "Processed: 11500 resumes.\n",
      "Processed: 12000 resumes.\n",
      "Processed: 12500 resumes.\n",
      "Processed: 13000 resumes.\n",
      "Processed: 13500 resumes.\n",
      "Processed: 14000 resumes.\n",
      "Processed: 14500 resumes.\n",
      "Processed: 15000 resumes.\n",
      "Processed: 15500 resumes.\n",
      "Processed: 16000 resumes.\n",
      "Processed: 16500 resumes.\n",
      "Processed: 17000 resumes.\n",
      "Processed: 17500 resumes.\n",
      "Processed: 18000 resumes.\n",
      "Processed: 18500 resumes.\n",
      "Processed: 19000 resumes.\n",
      "Processed: 19500 resumes.\n",
      "Processed: 20000 resumes.\n",
      "Processed: 20500 resumes.\n",
      "Processed: 21000 resumes.\n",
      "Processed: 21500 resumes.\n",
      "Processed: 22000 resumes.\n",
      "Processed: 22500 resumes.\n",
      "Processed: 23000 resumes.\n",
      "Processed: 23500 resumes.\n",
      "Processed: 24000 resumes.\n",
      "Processed: 24500 resumes.\n",
      "Processed: 25000 resumes.\n",
      "Processed: 25500 resumes.\n",
      "Processed: 26000 resumes.\n",
      "Processed: 26500 resumes.\n",
      "Processed: 27000 resumes.\n",
      "Processed: 27500 resumes.\n",
      "Processed: 28000 resumes.\n",
      "Processed: 28500 resumes.\n",
      "Processed: 29000 resumes.\n",
      "Processed: 29500 resumes.\n",
      "Processed: 30000 resumes.\n",
      "Processed: 30500 resumes.\n",
      "Processed: 31000 resumes.\n",
      "Processed: 31500 resumes.\n",
      "Processed: 32000 resumes.\n",
      "Processed: 32500 resumes.\n",
      "Processed: 33000 resumes.\n",
      "Processed: 33500 resumes.\n",
      "Processed: 34000 resumes.\n",
      "Processed: 34500 resumes.\n",
      "Processed: 35000 resumes.\n",
      "Processed: 35500 resumes.\n",
      "Processed: 36000 resumes.\n",
      "Processed: 36500 resumes.\n",
      "Processed: 37000 resumes.\n",
      "Processed: 37500 resumes.\n",
      "Processed: 38000 resumes.\n",
      "Processed: 38500 resumes.\n",
      "Processed: 39000 resumes.\n",
      "Processed: 39500 resumes.\n",
      "Processed: 40000 resumes.\n",
      "Processed: 40500 resumes.\n",
      "Processed: 41000 resumes.\n",
      "Processed: 41500 resumes.\n",
      "Processed: 42000 resumes.\n",
      "Processed: 42500 resumes.\n",
      "Processed: 43000 resumes.\n",
      "Processed: 43500 resumes.\n",
      "Processed: 44000 resumes.\n",
      "Processed: 44500 resumes.\n",
      "Processed: 45000 resumes.\n",
      "Processed: 45500 resumes.\n",
      "Processed: 46000 resumes.\n",
      "Processed: 46500 resumes.\n",
      "Processed: 47000 resumes.\n",
      "Processed: 47500 resumes.\n",
      "Processed: 48000 resumes.\n",
      "Processed: 48500 resumes.\n",
      "Processed: 49000 resumes.\n",
      "Processed: 49500 resumes.\n",
      "Processed: 50000 resumes.\n",
      "Processed: 50500 resumes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: indeed_com-job_deduped_n_merged_20170315_202047762763754.xml with elements:50054\n",
      "Starting processing: 50054 resumes.\n",
      "Processed: 0 resumes.\n",
      "Processed: 500 resumes.\n",
      "Processed: 1000 resumes.\n",
      "Processed: 1500 resumes.\n",
      "Processed: 2000 resumes.\n",
      "Processed: 2500 resumes.\n",
      "Processed: 3000 resumes.\n",
      "Processed: 3500 resumes.\n",
      "Processed: 4000 resumes.\n",
      "Processed: 4500 resumes.\n",
      "Processed: 5000 resumes.\n",
      "Processed: 5500 resumes.\n",
      "Processed: 6000 resumes.\n",
      "Processed: 6500 resumes.\n",
      "Processed: 7000 resumes.\n",
      "Processed: 7500 resumes.\n",
      "Processed: 8000 resumes.\n",
      "Processed: 8500 resumes.\n",
      "Processed: 9000 resumes.\n",
      "Processed: 9500 resumes.\n",
      "Processed: 10000 resumes.\n",
      "Processed: 10500 resumes.\n",
      "Processed: 11000 resumes.\n",
      "Processed: 11500 resumes.\n",
      "Processed: 12000 resumes.\n",
      "Processed: 12500 resumes.\n",
      "Processed: 13000 resumes.\n",
      "Processed: 13500 resumes.\n",
      "Processed: 14000 resumes.\n",
      "Processed: 14500 resumes.\n",
      "Processed: 15000 resumes.\n",
      "Processed: 15500 resumes.\n",
      "Processed: 16000 resumes.\n",
      "Processed: 16500 resumes.\n",
      "Processed: 17000 resumes.\n",
      "Processed: 17500 resumes.\n",
      "Processed: 18000 resumes.\n",
      "Processed: 18500 resumes.\n",
      "Processed: 19000 resumes.\n",
      "Processed: 19500 resumes.\n",
      "Processed: 20000 resumes.\n",
      "Processed: 20500 resumes.\n",
      "Processed: 21000 resumes.\n",
      "Processed: 21500 resumes.\n",
      "Processed: 22000 resumes.\n",
      "Processed: 22500 resumes.\n",
      "Processed: 23000 resumes.\n",
      "Processed: 23500 resumes.\n",
      "Processed: 24000 resumes.\n",
      "Processed: 24500 resumes.\n",
      "Processed: 25000 resumes.\n",
      "Processed: 25500 resumes.\n",
      "Processed: 26000 resumes.\n",
      "Processed: 26500 resumes.\n",
      "Processed: 27000 resumes.\n",
      "Processed: 27500 resumes.\n",
      "Processed: 28000 resumes.\n",
      "Processed: 28500 resumes.\n",
      "Processed: 29000 resumes.\n",
      "Processed: 29500 resumes.\n",
      "Processed: 30000 resumes.\n",
      "Processed: 30500 resumes.\n",
      "Processed: 31000 resumes.\n",
      "Processed: 31500 resumes.\n",
      "Processed: 32000 resumes.\n",
      "Processed: 32500 resumes.\n",
      "Processed: 33000 resumes.\n",
      "Processed: 33500 resumes.\n",
      "Processed: 34000 resumes.\n",
      "Processed: 34500 resumes.\n",
      "Processed: 35000 resumes.\n",
      "Processed: 35500 resumes.\n",
      "Processed: 36000 resumes.\n",
      "Processed: 36500 resumes.\n",
      "Processed: 37000 resumes.\n",
      "Processed: 37500 resumes.\n",
      "Processed: 38000 resumes.\n",
      "Processed: 38500 resumes.\n",
      "Processed: 39000 resumes.\n",
      "Processed: 39500 resumes.\n",
      "Processed: 40000 resumes.\n",
      "Processed: 40500 resumes.\n",
      "Processed: 41000 resumes.\n",
      "Processed: 41500 resumes.\n",
      "Processed: 42000 resumes.\n",
      "Processed: 42500 resumes.\n",
      "Processed: 43000 resumes.\n",
      "Processed: 43500 resumes.\n",
      "Processed: 44000 resumes.\n",
      "Processed: 44500 resumes.\n",
      "Processed: 45000 resumes.\n",
      "Processed: 45500 resumes.\n",
      "Processed: 46000 resumes.\n",
      "Processed: 46500 resumes.\n",
      "Processed: 47000 resumes.\n",
      "Processed: 47500 resumes.\n",
      "Processed: 48000 resumes.\n",
      "Processed: 48500 resumes.\n",
      "Processed: 49000 resumes.\n",
      "Processed: 49500 resumes.\n",
      "Processed: 50000 resumes.\n"
     ]
    }
   ],
   "source": [
    "companies = {}\n",
    "universities = {}\n",
    "certifications = {}\n",
    "skills_lump = []\n",
    "\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_201357376193103.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_202935841620141.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_201536923698467.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_203123248972746.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_201723769342220.xml')\n",
    "# read_raw_xml_and_push()\n",
    "\n",
    "read_next_xml('indeed_com-job_deduped_n_merged_20170315_203311012815474.xml')\n",
    "read_raw_xml_and_push()\n",
    "read_next_xml('indeed_com-job_deduped_n_merged_20170315_201906034655968.xml')\n",
    "read_raw_xml_and_push()\n",
    "read_next_xml('indeed_com-job_deduped_n_merged_20170315_203459248507509.xml')\n",
    "read_raw_xml_and_push()\n",
    "read_next_xml('indeed_com-job_deduped_n_merged_20170315_202047762763754.xml')\n",
    "read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_203646360307105.xml')\n",
    "# read_raw_xml_and_push()\n",
    "\n",
    "\n",
    "writeToFile('companies2', companies)\n",
    "writeToFile('universities2', universities)\n",
    "writeToFile('certifications2', certifications)\n",
    "writeToFile('skills_lump2', skills_lump)\n",
    "\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_203311012815474.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_201906034655968.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_203459248507509.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_202047762763754.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_203646360307105.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_202231085985935.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_203831771961790.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_202422140439578.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_204015128749914.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_202604394716786.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_204200995390445.xml')\n",
    "# read_raw_xml_and_push()\n",
    "# read_next_xml('indeed_com-job_deduped_n_merged_20170315_202751428419232.xml')\n",
    "# read_raw_xml_and_push()\n",
    "\n",
    "\n",
    "# writeToFile('companies', companies)\n",
    "# writeToFile('universities', universities)\n",
    "# writeToFile('certifications', certifications)\n",
    "# writeToFile('skills_lump', skills_lump)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: indeed_com-job_deduped_n_merged_20170315_201357376193103.xml with elements:50101\n"
     ]
    }
   ],
   "source": [
    "read_next_xml('indeed_com-job_deduped_n_merged_20170315_201357376193103.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xml_set = []\n",
    "dev_xml_set = []\n",
    "test_xml_set = []\n",
    "\n",
    "train_text_set = []\n",
    "dev_text_set = []\n",
    "test_text_set = []\n",
    "\n",
    "incompleteCount = 0\n",
    "\n",
    "def get_predicted_values_for_training(xml_snip):\n",
    "    if (xml_snip):\n",
    "        \n",
    "        work_title = xml_snip.find(\"p\", {\"class\": \"work_title\"})\n",
    "        if (work_title):\n",
    "            work_title = xml_snip.find(\"p\", {\"class\": \"work_title\"}).string\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "        work_stayed = False\n",
    "        work_dates = xml_snip.find(\"p\", {\"class\": \"work_dates\"})\n",
    "        if (work_dates):\n",
    "            work_dates = xml_snip.find(\"p\", {\"class\": \"work_dates\"}).string\n",
    "            if (\"to Present\" in work_dates):\n",
    "                work_stayed = True\n",
    "        else:\n",
    "            return []\n",
    "        \n",
    "        work_company = xml_snip.find(\"div\", {\"class\": \"work_company\"})\n",
    "        if (work_company):\n",
    "            work_company = xml_snip.find(\"div\", {\"class\": \"work_company\"}).find(\"span\", {\"class\": \"bold\"})\n",
    "            if (work_company):\n",
    "                work_company = xml_snip.find(\"div\", {\"class\": \"work_company\"}).find(\"span\", {\"class\": \"bold\"}).string\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "        work_description = xml_snip.find(\"p\", {\"class\": \"work_description\"})\n",
    "        if (work_description):\n",
    "            work_description = xml_snip.find(\"p\", {\"class\": \"work_description\"}).get_text()\n",
    "            work_description = unicodedata.normalize(\"NFKD\", work_description)\n",
    "        else:\n",
    "            work_description = \"\"\n",
    "\n",
    "        if (work_title and work_company):\n",
    "            workable_unit = {}\n",
    "            workable_unit['work_title'] = str(work_title)\n",
    "            workable_unit['work_company'] = work_company\n",
    "#             workable_unit['work_description'] = work_description\n",
    "            workable_unit['work_stayed'] = work_stayed\n",
    "            return workable_unit\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def read_raw_xml_and_extract_similar_jobtitle(go_through_all = 0):\n",
    "    global raw_xml\n",
    "    global incompleteCount\n",
    "    global train_xml_set\n",
    "    global train_text_set\n",
    "\n",
    "    go_through = go_through_all\n",
    "    if (not go_through_all):\n",
    "        go_through = len(raw_xml)\n",
    "    for i in range(go_through):\n",
    "        soup = BS(raw_xml[i], \"lxml\")\n",
    "        resumes = soup.findAll(\"div\", {\"class\": \"single_form-content\"})\n",
    "        for item in resumes:\n",
    "            print('Starting processing: ' + str(i+1) + \" resumes\")\n",
    "            all_work_exps = item.findAll(\"div\", {\"class\": \"work-experience-section\"})\n",
    "            if (all_work_exps and len(all_work_exps) > 1):\n",
    "                predictions = get_predicted_jobtitles(all_work_exps)\n",
    "                if (len(predictions) > 0):\n",
    "                    # extract and replace current job title\n",
    "                    first_work_exp = item.find(\"div\", {\"class\": \"work-experience-section\"})\n",
    "                    if (first_work_exp):\n",
    "                        string_comment = first_work_exp.find(\"p\", {\"class\": \"work_title\"})\n",
    "                        string_comment.replace_with(\"\")\n",
    "                        unit = {}\n",
    "                        unit['data'] = str(item)\n",
    "                        unit['predictions'] = predictions\n",
    "                        train_xml_set.append(unit)\n",
    "                        textunit = {}\n",
    "                        normalized_text = item.get_text()\n",
    "                        normalized_text = unicodedata.normalize(\"NFKD\", normalized_text)\n",
    "                        textunit['data'] = normalized_text\n",
    "                        textunit['predictions'] = predictions\n",
    "                        train_text_set.append(textunit)\n",
    "\n",
    "# remove everything after to for first job\n",
    "# if it has 'to present' they stayed\n",
    "        \n",
    "def read_raw_xml_and_extract_first(go_through_all = 0):\n",
    "    global raw_xml\n",
    "    global incompleteCount\n",
    "    global train_xml_set\n",
    "    global train_text_set\n",
    "\n",
    "    go_through = go_through_all\n",
    "    if (not go_through_all):\n",
    "        go_through = len(raw_xml)\n",
    "    for i in range(go_through):\n",
    "        soup = BS(raw_xml[i], \"lxml\")\n",
    "        resumes = soup.findAll(\"div\", {\"class\": \"single_form-content\"})\n",
    "        for item in resumes:\n",
    "            print('Starting processing: ' + str(i+1) + \" resumes\")\n",
    "            first_work_exp = item.find(\"div\", {\"class\": \"work-experience-section\"})\n",
    "            predictions = get_predicted_values_for_training(first_work_exp)\n",
    "            if (len(predictions) > 0):\n",
    "                # first_work_exp.extract()\n",
    "                work_dates = first_work_exp.find(\"p\", {\"class\": \"work_dates\"})\n",
    "                if (work_dates):\n",
    "                    string_comment = first_work_exp.find(\"p\", {\"class\": \"work_dates\"}).string\n",
    "                    sep = ' to '\n",
    "                    rest = string_comment.split(sep, 1)[0]\n",
    "                    work_dates.replace_with(rest)\n",
    "                unit = {}\n",
    "                unit['data'] = str(item)\n",
    "                unit['predictions'] = predictions\n",
    "                train_xml_set.append(unit)\n",
    "                textunit = {}\n",
    "                normalized_text = item.get_text()\n",
    "                normalized_text = unicodedata.normalize(\"NFKD\", normalized_text)\n",
    "                textunit['data'] = normalized_text\n",
    "                textunit['predictions'] = predictions\n",
    "                train_text_set.append(textunit)\n",
    "            else:\n",
    "                incompleteCount += 1\n",
    "\n",
    "def get_predicted_education(xml_snip):\n",
    "    edu_unit = {}\n",
    "    edu_unit['master'] = False\n",
    "    edu_unit['bachelor'] = False\n",
    "    \n",
    "    if (xml_snip):\n",
    "        \n",
    "        # Bachel or Maste -> <p class=\"edu_title\">\n",
    "        # college, univer -> <div class=\"edu_school\"><span class=\"bold\" itemprop=\"name\">\n",
    "        edu_titles = xml_snip.findAll(\"p\", {\"class\": \"edu_title\"})\n",
    "        if (edu_titles and len(edu_titles) > 0):\n",
    "            for item in edu_titles: # if (\"to Present\" in work_dates):\n",
    "                if ('bachel' in item.string.lower()) or ('master' in item.string.lower()) or ('phd' in item.string.lower()):\n",
    "                    edu_unit['bachelor'] = True\n",
    "                if ('master' in item.string.lower()) or ('phd' in item.string.lower()):\n",
    "                    edu_unit['master'] = True\n",
    "        \n",
    "        edu_unis = xml_snip.findAll(\"div\", {\"class\": \"edu_school\"})\n",
    "        if (edu_unis):\n",
    "            edu_unis = xml_snip.findAll(\"div\", {\"class\": \"edu_school\"})\n",
    "            if (edu_unis and len(edu_unis) > 0):\n",
    "                for item in edu_unis:\n",
    "                    edu_span = item.find(\"span\", {\"class\": \"bold\"})\n",
    "                    if (edu_span and edu_span.string):\n",
    "                        if ('universi' in edu_span.string.lower()) or ('college' in edu_span.string.lower()):\n",
    "                            edu_unit['bachelor'] = True\n",
    "                        \n",
    "    return edu_unit\n",
    "\n",
    "def read_raw_xml_and_extract_education(go_through_all = 0):\n",
    "    global raw_xml\n",
    "    global incompleteCount\n",
    "    global train_xml_set\n",
    "    global train_text_set\n",
    "\n",
    "    go_through = go_through_all\n",
    "    if (not go_through_all):\n",
    "        go_through = len(raw_xml)\n",
    "    for i in range(go_through):\n",
    "        soup = BS(raw_xml[i], \"lxml\")\n",
    "        resumes = soup.findAll(\"div\", {\"class\": \"single_form-content\"})\n",
    "        for item in resumes:\n",
    "            print('Starting processing: ' + str(i+1) + \" resumes\")\n",
    "            education = item.find(\"div\", {\"id\": \"education-items\"})\n",
    "            predictions = get_predicted_education(education)\n",
    "            education_items = item.find(\"div\", {\"class\": \"education-content\"})\n",
    "            if (education_items):\n",
    "                education_items.extract()\n",
    "            unit = {}\n",
    "            unit['data'] = str(item)\n",
    "            unit['predictions'] = predictions\n",
    "            train_xml_set.append(unit)\n",
    "            textunit = {}\n",
    "            normalized_text = item.get_text()\n",
    "            normalized_text = unicodedata.normalize(\"NFKD\", normalized_text)\n",
    "            textunit['data'] = normalized_text\n",
    "            textunit['predictions'] = predictions\n",
    "            train_text_set.append(textunit)\n",
    "\n",
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]\n",
    "\n",
    "def get_predicted_jobtitles(past_jobs):\n",
    "    work_unit = {}\n",
    "    work_unit['similar_job'] = False\n",
    "    work_unit['similar_metric'] = 0.0\n",
    "    work_unit['similar_job_titles'] = []\n",
    "    \n",
    "    first_job = \"\"\n",
    "    second_job = \"\"\n",
    "    \n",
    "    if (past_jobs and len(past_jobs) > 0):\n",
    "        for index, item in enumerate(past_jobs):\n",
    "            string_comment = item.find(\"p\", {\"class\": \"work_title\"})\n",
    "            if (index == 0 and string_comment):\n",
    "                string_comment = item.find(\"p\", {\"class\": \"work_title\"}).string\n",
    "                if (string_comment and len(string_comment) > 2):\n",
    "                    first_job = string_comment\n",
    "            if (index == 1 and string_comment):\n",
    "                string_comment = item.find(\"p\", {\"class\": \"work_title\"}).string\n",
    "                if (string_comment and len(string_comment) > 2):\n",
    "                    second_job = string_comment\n",
    "    \n",
    "    if (first_job and second_job):\n",
    "        tokens_first = first_job.lower().replace('[^a-zA-Z ]',' ').split()\n",
    "        tokens_second = second_job.lower().replace('[^a-zA-Z ]',' ').split()\n",
    "        for value in tokens_first:\n",
    "            if value in tokens_second:\n",
    "                 work_unit['similar_job'] = True\n",
    "        \n",
    "        work_unit['similar_metric'] = levenshtein(first_job.lower().replace('[^a-zA-Z ]',' '), second_job.lower().replace('[^a-zA-Z ]',' '))\n",
    "        work_unit['similar_job_titles'].append(first_job.lower().replace('[^a-zA-Z ]',' '))\n",
    "        work_unit['similar_job_titles'].append(second_job.lower().replace('[^a-zA-Z ]',' '))\n",
    "\n",
    "        return work_unit\n",
    "\n",
    "    return []\n",
    "\n",
    "def get_predicted_work_experience(past_jobs):\n",
    "    work_unit = {}\n",
    "    work_unit['years'] = False\n",
    "    \n",
    "    first_job = \"\"\n",
    "    second_job = \"\"\n",
    "    pattern = re.compile(r'((19|20)[0-9]{2})')\n",
    "    \n",
    "    if (past_jobs and len(past_jobs) > 0):\n",
    "        for index, item in enumerate(past_jobs):\n",
    "            work_dates = item.find(\"p\", {\"class\": \"work_dates\"})\n",
    "            if (work_dates):\n",
    "                work_dates = item.find(\"p\", {\"class\": \"work_dates\"}).string\n",
    "                # (19|20)[0-9]{2}\n",
    "                for (date1, date2) in re.findall(pattern, work_dates):\n",
    "                    if (int(date1) < 2007):\n",
    "                        work_unit['years'] = True\n",
    "            \n",
    "        return work_unit\n",
    "\n",
    "    return []\n",
    "\n",
    "def read_raw_xml_and_extract_work_years(go_through_all = 0):\n",
    "    global raw_xml\n",
    "    global incompleteCount\n",
    "    global train_xml_set\n",
    "    global train_text_set\n",
    "\n",
    "    go_through = go_through_all\n",
    "    if (not go_through_all):\n",
    "        go_through = len(raw_xml)\n",
    "    for i in range(go_through):\n",
    "        soup = BS(raw_xml[i], \"lxml\")\n",
    "        resumes = soup.findAll(\"div\", {\"class\": \"single_form-content\"})\n",
    "        for item in resumes:\n",
    "            print('Starting processing: ' + str(i+1) + \" resumes\")\n",
    "            all_work_exps = item.findAll(\"div\", {\"class\": \"work-experience-section\"})\n",
    "            if (all_work_exps and len(all_work_exps) > 1):\n",
    "                predictions = get_predicted_work_experience(all_work_exps)\n",
    "                if (len(predictions) > 0):\n",
    "                    # extract and replace current job title\n",
    "                    unit = {}\n",
    "                    unit['data'] = str(item)\n",
    "                    unit['predictions'] = predictions\n",
    "#                     print(predictions)\n",
    "                    train_xml_set.append(unit)\n",
    "                    textunit = {}\n",
    "                    normalized_text = item.get_text()\n",
    "                    normalized_text = unicodedata.normalize(\"NFKD\", normalized_text)\n",
    "                    textunit['data'] = normalized_text\n",
    "                    textunit['predictions'] = predictions\n",
    "                    train_text_set.append(textunit)\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing: 1 resumes\n",
      "Starting processing: 2 resumes\n",
      "Starting processing: 3 resumes\n",
      "Starting processing: 4 resumes\n",
      "Starting processing: 5 resumes\n",
      "Starting processing: 6 resumes\n",
      "Starting processing: 7 resumes\n",
      "Starting processing: 8 resumes\n",
      "Starting processing: 9 resumes\n",
      "Starting processing: 10 resumes\n",
      "Starting processing: 11 resumes\n",
      "Starting processing: 12 resumes\n",
      "Starting processing: 13 resumes\n",
      "Starting processing: 14 resumes\n",
      "Starting processing: 15 resumes\n",
      "Starting processing: 16 resumes\n",
      "Starting processing: 17 resumes\n",
      "Starting processing: 18 resumes\n",
      "Starting processing: 19 resumes\n",
      "Starting processing: 20 resumes\n",
      "Starting processing: 21 resumes\n",
      "Starting processing: 22 resumes\n",
      "Starting processing: 23 resumes\n",
      "Starting processing: 24 resumes\n",
      "Starting processing: 25 resumes\n",
      "Starting processing: 26 resumes\n",
      "Starting processing: 27 resumes\n",
      "Starting processing: 28 resumes\n",
      "Starting processing: 29 resumes\n",
      "Starting processing: 30 resumes\n",
      "Starting processing: 31 resumes\n",
      "Starting processing: 32 resumes\n",
      "Starting processing: 33 resumes\n",
      "Starting processing: 34 resumes\n",
      "Starting processing: 35 resumes\n",
      "Starting processing: 36 resumes\n",
      "Starting processing: 37 resumes\n",
      "Starting processing: 38 resumes\n",
      "Starting processing: 39 resumes\n",
      "Starting processing: 40 resumes\n",
      "Starting processing: 41 resumes\n",
      "Starting processing: 42 resumes\n",
      "Starting processing: 43 resumes\n",
      "Starting processing: 44 resumes\n",
      "Starting processing: 45 resumes\n",
      "Starting processing: 46 resumes\n",
      "Starting processing: 47 resumes\n",
      "Starting processing: 48 resumes\n",
      "Starting processing: 49 resumes\n",
      "Starting processing: 50 resumes\n",
      "Starting processing: 51 resumes\n",
      "Starting processing: 52 resumes\n",
      "Starting processing: 53 resumes\n",
      "Starting processing: 54 resumes\n",
      "Starting processing: 55 resumes\n",
      "Starting processing: 56 resumes\n",
      "Starting processing: 57 resumes\n",
      "Starting processing: 58 resumes\n",
      "Starting processing: 59 resumes\n",
      "Starting processing: 60 resumes\n",
      "Starting processing: 61 resumes\n",
      "Starting processing: 62 resumes\n",
      "Starting processing: 63 resumes\n",
      "Starting processing: 64 resumes\n",
      "Starting processing: 65 resumes\n",
      "Starting processing: 66 resumes\n",
      "Starting processing: 67 resumes\n",
      "Starting processing: 68 resumes\n",
      "Starting processing: 69 resumes\n",
      "Starting processing: 70 resumes\n",
      "Starting processing: 71 resumes\n",
      "Starting processing: 72 resumes\n",
      "Starting processing: 73 resumes\n",
      "Starting processing: 74 resumes\n",
      "Starting processing: 75 resumes\n",
      "Starting processing: 76 resumes\n",
      "Starting processing: 77 resumes\n",
      "Starting processing: 78 resumes\n",
      "Starting processing: 79 resumes\n",
      "Starting processing: 80 resumes\n",
      "Starting processing: 81 resumes\n",
      "Starting processing: 82 resumes\n",
      "Starting processing: 83 resumes\n",
      "Starting processing: 84 resumes\n",
      "Starting processing: 85 resumes\n",
      "Starting processing: 86 resumes\n",
      "Starting processing: 87 resumes\n",
      "Starting processing: 88 resumes\n",
      "Starting processing: 89 resumes\n",
      "Starting processing: 90 resumes\n",
      "Starting processing: 91 resumes\n",
      "Starting processing: 92 resumes\n",
      "Starting processing: 93 resumes\n",
      "Starting processing: 94 resumes\n",
      "Starting processing: 95 resumes\n",
      "Starting processing: 96 resumes\n",
      "Starting processing: 97 resumes\n",
      "Starting processing: 98 resumes\n",
      "Starting processing: 99 resumes\n",
      "Starting processing: 100 resumes\n",
      "Starting processing: 101 resumes\n",
      "Starting processing: 102 resumes\n",
      "Starting processing: 103 resumes\n",
      "Starting processing: 104 resumes\n",
      "Starting processing: 105 resumes\n",
      "Starting processing: 106 resumes\n",
      "Starting processing: 107 resumes\n",
      "Starting processing: 108 resumes\n",
      "Starting processing: 109 resumes\n",
      "Starting processing: 110 resumes\n",
      "Starting processing: 111 resumes\n",
      "Starting processing: 112 resumes\n",
      "Starting processing: 113 resumes\n",
      "Starting processing: 114 resumes\n",
      "Starting processing: 115 resumes\n",
      "Starting processing: 116 resumes\n",
      "Starting processing: 117 resumes\n",
      "Starting processing: 118 resumes\n",
      "Starting processing: 119 resumes\n",
      "Starting processing: 120 resumes\n",
      "Starting processing: 121 resumes\n",
      "Starting processing: 122 resumes\n",
      "Starting processing: 123 resumes\n",
      "Starting processing: 124 resumes\n",
      "Starting processing: 125 resumes\n",
      "Starting processing: 126 resumes\n",
      "Starting processing: 127 resumes\n",
      "Starting processing: 128 resumes\n",
      "Starting processing: 129 resumes\n",
      "Starting processing: 130 resumes\n",
      "Starting processing: 131 resumes\n",
      "Starting processing: 132 resumes\n",
      "Starting processing: 133 resumes\n",
      "Starting processing: 134 resumes\n",
      "Starting processing: 135 resumes\n",
      "Starting processing: 136 resumes\n",
      "Starting processing: 137 resumes\n",
      "Starting processing: 138 resumes\n",
      "Starting processing: 139 resumes\n",
      "Starting processing: 140 resumes\n",
      "Starting processing: 141 resumes\n",
      "Starting processing: 142 resumes\n",
      "Starting processing: 143 resumes\n",
      "Starting processing: 144 resumes\n",
      "Starting processing: 145 resumes\n",
      "Starting processing: 146 resumes\n",
      "Starting processing: 147 resumes\n",
      "Starting processing: 148 resumes\n",
      "Starting processing: 149 resumes\n",
      "Starting processing: 150 resumes\n",
      "Starting processing: 151 resumes\n",
      "Starting processing: 152 resumes\n",
      "Starting processing: 153 resumes\n",
      "Starting processing: 154 resumes\n",
      "Starting processing: 155 resumes\n",
      "Starting processing: 156 resumes\n",
      "Starting processing: 157 resumes\n",
      "Starting processing: 158 resumes\n",
      "Starting processing: 159 resumes\n",
      "Starting processing: 160 resumes\n",
      "Starting processing: 161 resumes\n",
      "Starting processing: 162 resumes\n",
      "Starting processing: 163 resumes\n",
      "Starting processing: 164 resumes\n",
      "Starting processing: 165 resumes\n",
      "Starting processing: 166 resumes\n",
      "Starting processing: 167 resumes\n",
      "Starting processing: 168 resumes\n",
      "Starting processing: 169 resumes\n",
      "Starting processing: 170 resumes\n",
      "Starting processing: 171 resumes\n",
      "Starting processing: 172 resumes\n",
      "Starting processing: 173 resumes\n",
      "Starting processing: 174 resumes\n",
      "Starting processing: 175 resumes\n",
      "Starting processing: 176 resumes\n",
      "Starting processing: 177 resumes\n",
      "Starting processing: 178 resumes\n",
      "Starting processing: 179 resumes\n",
      "Starting processing: 180 resumes\n",
      "Starting processing: 181 resumes\n",
      "Starting processing: 182 resumes\n",
      "Starting processing: 183 resumes\n",
      "Starting processing: 184 resumes\n",
      "Starting processing: 185 resumes\n",
      "Starting processing: 186 resumes\n",
      "Starting processing: 187 resumes\n",
      "Starting processing: 188 resumes\n",
      "Starting processing: 189 resumes\n",
      "Starting processing: 190 resumes\n",
      "Starting processing: 191 resumes\n",
      "Starting processing: 192 resumes\n",
      "Starting processing: 193 resumes\n",
      "Starting processing: 194 resumes\n",
      "Starting processing: 195 resumes\n",
      "Starting processing: 196 resumes\n",
      "Starting processing: 197 resumes\n",
      "Starting processing: 198 resumes\n",
      "Starting processing: 199 resumes\n",
      "Starting processing: 200 resumes\n",
      "Starting processing: 201 resumes\n",
      "Starting processing: 202 resumes\n",
      "Starting processing: 203 resumes\n",
      "Starting processing: 204 resumes\n",
      "Starting processing: 205 resumes\n",
      "Starting processing: 206 resumes\n",
      "Starting processing: 207 resumes\n",
      "Starting processing: 208 resumes\n",
      "Starting processing: 209 resumes\n",
      "Starting processing: 210 resumes\n",
      "Starting processing: 211 resumes\n",
      "Starting processing: 212 resumes\n",
      "Starting processing: 213 resumes\n",
      "Starting processing: 214 resumes\n",
      "Starting processing: 215 resumes\n",
      "Starting processing: 216 resumes\n",
      "Starting processing: 217 resumes\n",
      "Starting processing: 218 resumes\n",
      "Starting processing: 219 resumes\n",
      "Starting processing: 220 resumes\n",
      "Starting processing: 221 resumes\n",
      "Starting processing: 222 resumes\n",
      "Starting processing: 223 resumes\n",
      "Starting processing: 224 resumes\n",
      "Starting processing: 225 resumes\n",
      "Starting processing: 226 resumes\n",
      "Starting processing: 227 resumes\n",
      "Starting processing: 228 resumes\n",
      "Starting processing: 229 resumes\n",
      "Starting processing: 230 resumes\n",
      "Starting processing: 231 resumes\n",
      "Starting processing: 232 resumes\n",
      "Starting processing: 233 resumes\n",
      "Starting processing: 234 resumes\n",
      "Starting processing: 235 resumes\n",
      "Starting processing: 236 resumes\n",
      "Starting processing: 237 resumes\n",
      "Starting processing: 238 resumes\n",
      "Starting processing: 239 resumes\n",
      "Starting processing: 240 resumes\n",
      "Starting processing: 241 resumes\n",
      "Starting processing: 242 resumes\n",
      "Starting processing: 243 resumes\n",
      "Starting processing: 244 resumes\n",
      "Starting processing: 245 resumes\n",
      "Starting processing: 246 resumes\n",
      "Starting processing: 247 resumes\n",
      "Starting processing: 248 resumes\n",
      "Starting processing: 249 resumes\n",
      "Starting processing: 250 resumes\n",
      "Starting processing: 251 resumes\n",
      "Starting processing: 252 resumes\n",
      "Starting processing: 253 resumes\n",
      "Starting processing: 254 resumes\n",
      "Starting processing: 255 resumes\n",
      "Starting processing: 256 resumes\n",
      "Starting processing: 257 resumes\n",
      "Starting processing: 258 resumes\n",
      "Starting processing: 259 resumes\n",
      "Starting processing: 260 resumes\n",
      "Starting processing: 261 resumes\n",
      "Starting processing: 262 resumes\n",
      "Starting processing: 263 resumes\n",
      "Starting processing: 264 resumes\n",
      "Starting processing: 265 resumes\n",
      "Starting processing: 266 resumes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing: 267 resumes\n",
      "Starting processing: 268 resumes\n",
      "Starting processing: 269 resumes\n",
      "Starting processing: 270 resumes\n",
      "Starting processing: 271 resumes\n",
      "Starting processing: 272 resumes\n",
      "Starting processing: 273 resumes\n",
      "Starting processing: 274 resumes\n",
      "Starting processing: 275 resumes\n",
      "Starting processing: 276 resumes\n",
      "Starting processing: 277 resumes\n",
      "Starting processing: 278 resumes\n",
      "Starting processing: 279 resumes\n",
      "Starting processing: 280 resumes\n",
      "Starting processing: 281 resumes\n",
      "Starting processing: 282 resumes\n",
      "Starting processing: 283 resumes\n",
      "Starting processing: 284 resumes\n",
      "Starting processing: 285 resumes\n",
      "Starting processing: 286 resumes\n",
      "Starting processing: 287 resumes\n",
      "Starting processing: 288 resumes\n",
      "Starting processing: 289 resumes\n",
      "Starting processing: 290 resumes\n",
      "Starting processing: 291 resumes\n",
      "Starting processing: 292 resumes\n",
      "Starting processing: 293 resumes\n",
      "Starting processing: 294 resumes\n",
      "Starting processing: 295 resumes\n",
      "Starting processing: 296 resumes\n",
      "Starting processing: 297 resumes\n",
      "Starting processing: 298 resumes\n",
      "Starting processing: 299 resumes\n",
      "Starting processing: 300 resumes\n",
      "Starting processing: 301 resumes\n",
      "Starting processing: 302 resumes\n",
      "Starting processing: 303 resumes\n",
      "Starting processing: 304 resumes\n",
      "Starting processing: 305 resumes\n",
      "Starting processing: 306 resumes\n",
      "Starting processing: 307 resumes\n",
      "Starting processing: 308 resumes\n",
      "Starting processing: 309 resumes\n",
      "Starting processing: 310 resumes\n",
      "Starting processing: 311 resumes\n",
      "Starting processing: 312 resumes\n",
      "Starting processing: 313 resumes\n",
      "Starting processing: 314 resumes\n",
      "Starting processing: 315 resumes\n",
      "Starting processing: 316 resumes\n",
      "Starting processing: 317 resumes\n",
      "Starting processing: 318 resumes\n",
      "Starting processing: 319 resumes\n",
      "Starting processing: 320 resumes\n",
      "Starting processing: 321 resumes\n",
      "Starting processing: 322 resumes\n",
      "Starting processing: 323 resumes\n",
      "Starting processing: 324 resumes\n",
      "Starting processing: 325 resumes\n",
      "Starting processing: 326 resumes\n",
      "Starting processing: 327 resumes\n",
      "Starting processing: 328 resumes\n",
      "Starting processing: 329 resumes\n",
      "Starting processing: 330 resumes\n",
      "Starting processing: 331 resumes\n",
      "Starting processing: 332 resumes\n",
      "Starting processing: 333 resumes\n",
      "Starting processing: 334 resumes\n",
      "Starting processing: 335 resumes\n",
      "Starting processing: 336 resumes\n",
      "Starting processing: 337 resumes\n",
      "Starting processing: 338 resumes\n",
      "Starting processing: 339 resumes\n",
      "Starting processing: 340 resumes\n",
      "Starting processing: 341 resumes\n",
      "Starting processing: 342 resumes\n",
      "Starting processing: 343 resumes\n",
      "Starting processing: 344 resumes\n",
      "Starting processing: 345 resumes\n",
      "Starting processing: 346 resumes\n",
      "Starting processing: 347 resumes\n",
      "Starting processing: 348 resumes\n",
      "Starting processing: 349 resumes\n",
      "Starting processing: 350 resumes\n",
      "Starting processing: 351 resumes\n",
      "Starting processing: 352 resumes\n",
      "Starting processing: 353 resumes\n",
      "Starting processing: 354 resumes\n",
      "Starting processing: 355 resumes\n",
      "Starting processing: 356 resumes\n",
      "Starting processing: 357 resumes\n",
      "Starting processing: 358 resumes\n",
      "Starting processing: 359 resumes\n",
      "Starting processing: 360 resumes\n",
      "Starting processing: 361 resumes\n",
      "Starting processing: 362 resumes\n",
      "Starting processing: 363 resumes\n",
      "Starting processing: 364 resumes\n",
      "Starting processing: 365 resumes\n",
      "Starting processing: 366 resumes\n",
      "Starting processing: 367 resumes\n",
      "Starting processing: 368 resumes\n",
      "Starting processing: 369 resumes\n",
      "Starting processing: 370 resumes\n",
      "Starting processing: 371 resumes\n",
      "Starting processing: 372 resumes\n",
      "Starting processing: 373 resumes\n",
      "Starting processing: 374 resumes\n",
      "Starting processing: 375 resumes\n",
      "Starting processing: 376 resumes\n",
      "Starting processing: 377 resumes\n",
      "Starting processing: 378 resumes\n",
      "Starting processing: 379 resumes\n",
      "Starting processing: 380 resumes\n",
      "Starting processing: 381 resumes\n",
      "Starting processing: 382 resumes\n",
      "Starting processing: 383 resumes\n",
      "Starting processing: 384 resumes\n",
      "Starting processing: 385 resumes\n",
      "Starting processing: 386 resumes\n",
      "Starting processing: 387 resumes\n",
      "Starting processing: 388 resumes\n",
      "Starting processing: 389 resumes\n",
      "Starting processing: 390 resumes\n",
      "Starting processing: 391 resumes\n",
      "Starting processing: 392 resumes\n",
      "Starting processing: 393 resumes\n",
      "Starting processing: 394 resumes\n",
      "Starting processing: 395 resumes\n",
      "Starting processing: 396 resumes\n",
      "Starting processing: 397 resumes\n",
      "Starting processing: 398 resumes\n",
      "Starting processing: 399 resumes\n",
      "Starting processing: 400 resumes\n",
      "Starting processing: 401 resumes\n",
      "Starting processing: 402 resumes\n",
      "Starting processing: 403 resumes\n",
      "Starting processing: 404 resumes\n",
      "Starting processing: 405 resumes\n",
      "Starting processing: 406 resumes\n",
      "Starting processing: 407 resumes\n",
      "Starting processing: 408 resumes\n",
      "Starting processing: 409 resumes\n",
      "Starting processing: 410 resumes\n",
      "Starting processing: 411 resumes\n",
      "Starting processing: 412 resumes\n",
      "Starting processing: 413 resumes\n",
      "Starting processing: 414 resumes\n",
      "Starting processing: 415 resumes\n",
      "Starting processing: 416 resumes\n",
      "Starting processing: 417 resumes\n",
      "Starting processing: 418 resumes\n",
      "Starting processing: 419 resumes\n",
      "Starting processing: 420 resumes\n",
      "Starting processing: 421 resumes\n",
      "Starting processing: 422 resumes\n",
      "Starting processing: 423 resumes\n",
      "Starting processing: 424 resumes\n",
      "Starting processing: 425 resumes\n",
      "Starting processing: 426 resumes\n",
      "Starting processing: 427 resumes\n",
      "Starting processing: 428 resumes\n",
      "Starting processing: 429 resumes\n",
      "Starting processing: 430 resumes\n",
      "Starting processing: 431 resumes\n",
      "Starting processing: 432 resumes\n",
      "Starting processing: 433 resumes\n",
      "Starting processing: 434 resumes\n",
      "Starting processing: 435 resumes\n",
      "Starting processing: 436 resumes\n",
      "Starting processing: 437 resumes\n",
      "Starting processing: 438 resumes\n",
      "Starting processing: 439 resumes\n",
      "Starting processing: 440 resumes\n",
      "Starting processing: 441 resumes\n",
      "Starting processing: 442 resumes\n",
      "Starting processing: 443 resumes\n",
      "Starting processing: 444 resumes\n",
      "Starting processing: 445 resumes\n",
      "Starting processing: 446 resumes\n",
      "Starting processing: 447 resumes\n",
      "Starting processing: 448 resumes\n",
      "Starting processing: 449 resumes\n",
      "Starting processing: 450 resumes\n",
      "Starting processing: 451 resumes\n",
      "Starting processing: 452 resumes\n",
      "Starting processing: 453 resumes\n",
      "Starting processing: 454 resumes\n",
      "Starting processing: 455 resumes\n",
      "Starting processing: 456 resumes\n",
      "Starting processing: 457 resumes\n",
      "Starting processing: 458 resumes\n",
      "Starting processing: 459 resumes\n",
      "Starting processing: 460 resumes\n",
      "Starting processing: 461 resumes\n",
      "Starting processing: 462 resumes\n",
      "Starting processing: 463 resumes\n",
      "Starting processing: 464 resumes\n",
      "Starting processing: 465 resumes\n",
      "Starting processing: 466 resumes\n",
      "Starting processing: 467 resumes\n",
      "Starting processing: 468 resumes\n",
      "Starting processing: 469 resumes\n",
      "Starting processing: 470 resumes\n",
      "Starting processing: 471 resumes\n",
      "Starting processing: 472 resumes\n",
      "Starting processing: 473 resumes\n",
      "Starting processing: 474 resumes\n",
      "Starting processing: 475 resumes\n",
      "Starting processing: 476 resumes\n",
      "Starting processing: 477 resumes\n",
      "Starting processing: 478 resumes\n",
      "Starting processing: 479 resumes\n",
      "Starting processing: 480 resumes\n",
      "Starting processing: 481 resumes\n",
      "Starting processing: 482 resumes\n",
      "Starting processing: 483 resumes\n",
      "Starting processing: 484 resumes\n",
      "Starting processing: 485 resumes\n",
      "Starting processing: 486 resumes\n",
      "Starting processing: 487 resumes\n",
      "Starting processing: 488 resumes\n",
      "Starting processing: 489 resumes\n",
      "Starting processing: 490 resumes\n",
      "Starting processing: 491 resumes\n",
      "Starting processing: 492 resumes\n",
      "Starting processing: 493 resumes\n",
      "Starting processing: 494 resumes\n",
      "Starting processing: 495 resumes\n",
      "Starting processing: 496 resumes\n",
      "Starting processing: 497 resumes\n",
      "Starting processing: 498 resumes\n",
      "Starting processing: 499 resumes\n",
      "Starting processing: 500 resumes\n",
      "Starting processing: 501 resumes\n",
      "Starting processing: 502 resumes\n",
      "Starting processing: 503 resumes\n",
      "Starting processing: 504 resumes\n",
      "Starting processing: 505 resumes\n",
      "Starting processing: 506 resumes\n",
      "Starting processing: 507 resumes\n",
      "Starting processing: 508 resumes\n",
      "Starting processing: 509 resumes\n",
      "Starting processing: 510 resumes\n",
      "Starting processing: 511 resumes\n",
      "Starting processing: 512 resumes\n",
      "Starting processing: 513 resumes\n",
      "Starting processing: 514 resumes\n",
      "Starting processing: 515 resumes\n",
      "Starting processing: 516 resumes\n",
      "Starting processing: 517 resumes\n",
      "Starting processing: 518 resumes\n",
      "Starting processing: 519 resumes\n",
      "Starting processing: 520 resumes\n",
      "Starting processing: 521 resumes\n",
      "Starting processing: 522 resumes\n",
      "Starting processing: 523 resumes\n",
      "Starting processing: 524 resumes\n",
      "Starting processing: 525 resumes\n",
      "Starting processing: 526 resumes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing: 527 resumes\n",
      "Starting processing: 528 resumes\n",
      "Starting processing: 529 resumes\n",
      "Starting processing: 530 resumes\n",
      "Starting processing: 531 resumes\n",
      "Starting processing: 532 resumes\n",
      "Starting processing: 533 resumes\n",
      "Starting processing: 534 resumes\n",
      "Starting processing: 535 resumes\n",
      "Starting processing: 536 resumes\n",
      "Starting processing: 537 resumes\n",
      "Starting processing: 538 resumes\n",
      "Starting processing: 539 resumes\n",
      "Starting processing: 540 resumes\n",
      "Starting processing: 541 resumes\n",
      "Starting processing: 542 resumes\n",
      "Starting processing: 543 resumes\n",
      "Starting processing: 544 resumes\n",
      "Starting processing: 545 resumes\n",
      "Starting processing: 546 resumes\n",
      "Starting processing: 547 resumes\n",
      "Starting processing: 548 resumes\n",
      "Starting processing: 549 resumes\n",
      "Starting processing: 550 resumes\n",
      "Starting processing: 551 resumes\n",
      "Starting processing: 552 resumes\n",
      "Starting processing: 553 resumes\n",
      "Starting processing: 554 resumes\n",
      "Starting processing: 555 resumes\n",
      "Starting processing: 556 resumes\n",
      "Starting processing: 557 resumes\n",
      "Starting processing: 558 resumes\n",
      "Starting processing: 559 resumes\n",
      "Starting processing: 560 resumes\n",
      "Starting processing: 561 resumes\n",
      "Starting processing: 562 resumes\n",
      "Starting processing: 563 resumes\n",
      "Starting processing: 564 resumes\n",
      "Starting processing: 565 resumes\n",
      "Starting processing: 566 resumes\n",
      "Starting processing: 567 resumes\n",
      "Starting processing: 568 resumes\n",
      "Starting processing: 569 resumes\n",
      "Starting processing: 570 resumes\n",
      "Starting processing: 571 resumes\n",
      "Starting processing: 572 resumes\n",
      "Starting processing: 573 resumes\n",
      "Starting processing: 574 resumes\n",
      "Starting processing: 575 resumes\n",
      "Starting processing: 576 resumes\n",
      "Starting processing: 577 resumes\n",
      "Starting processing: 578 resumes\n",
      "Starting processing: 579 resumes\n",
      "Starting processing: 580 resumes\n",
      "Starting processing: 581 resumes\n",
      "Starting processing: 582 resumes\n",
      "Starting processing: 583 resumes\n",
      "Starting processing: 584 resumes\n",
      "Starting processing: 585 resumes\n",
      "Starting processing: 586 resumes\n",
      "Starting processing: 587 resumes\n",
      "Starting processing: 588 resumes\n",
      "Starting processing: 589 resumes\n",
      "Starting processing: 590 resumes\n",
      "Starting processing: 591 resumes\n",
      "Starting processing: 592 resumes\n",
      "Starting processing: 593 resumes\n",
      "Starting processing: 594 resumes\n",
      "Starting processing: 595 resumes\n",
      "Starting processing: 596 resumes\n",
      "Starting processing: 597 resumes\n",
      "Starting processing: 598 resumes\n",
      "Starting processing: 599 resumes\n",
      "Starting processing: 600 resumes\n",
      "Starting processing: 601 resumes\n",
      "Starting processing: 602 resumes\n",
      "Starting processing: 603 resumes\n",
      "Starting processing: 604 resumes\n",
      "Starting processing: 605 resumes\n",
      "Starting processing: 606 resumes\n",
      "Starting processing: 607 resumes\n",
      "Starting processing: 608 resumes\n",
      "Starting processing: 609 resumes\n",
      "Starting processing: 610 resumes\n",
      "Starting processing: 611 resumes\n",
      "Starting processing: 612 resumes\n",
      "Starting processing: 613 resumes\n",
      "Starting processing: 614 resumes\n",
      "Starting processing: 615 resumes\n",
      "Starting processing: 616 resumes\n",
      "Starting processing: 617 resumes\n",
      "Starting processing: 618 resumes\n",
      "Starting processing: 619 resumes\n",
      "Starting processing: 620 resumes\n",
      "Starting processing: 621 resumes\n",
      "Starting processing: 622 resumes\n",
      "Starting processing: 623 resumes\n",
      "Starting processing: 624 resumes\n",
      "Starting processing: 625 resumes\n",
      "Starting processing: 626 resumes\n",
      "Starting processing: 627 resumes\n",
      "Starting processing: 628 resumes\n",
      "Starting processing: 629 resumes\n",
      "Starting processing: 630 resumes\n",
      "Starting processing: 631 resumes\n",
      "Starting processing: 632 resumes\n",
      "Starting processing: 633 resumes\n",
      "Starting processing: 634 resumes\n",
      "Starting processing: 635 resumes\n",
      "Starting processing: 636 resumes\n",
      "Starting processing: 637 resumes\n",
      "Starting processing: 638 resumes\n",
      "Starting processing: 639 resumes\n",
      "Starting processing: 640 resumes\n",
      "Starting processing: 641 resumes\n",
      "Starting processing: 642 resumes\n",
      "Starting processing: 643 resumes\n",
      "Starting processing: 644 resumes\n",
      "Starting processing: 645 resumes\n",
      "Starting processing: 646 resumes\n",
      "Starting processing: 647 resumes\n",
      "Starting processing: 648 resumes\n",
      "Starting processing: 649 resumes\n",
      "Starting processing: 650 resumes\n",
      "Starting processing: 651 resumes\n",
      "Starting processing: 652 resumes\n",
      "Starting processing: 653 resumes\n",
      "Starting processing: 654 resumes\n",
      "Starting processing: 655 resumes\n",
      "Starting processing: 656 resumes\n",
      "Starting processing: 657 resumes\n",
      "Starting processing: 658 resumes\n",
      "Starting processing: 659 resumes\n",
      "Starting processing: 660 resumes\n",
      "Starting processing: 661 resumes\n",
      "Starting processing: 662 resumes\n",
      "Starting processing: 663 resumes\n",
      "Starting processing: 664 resumes\n",
      "Starting processing: 665 resumes\n",
      "Starting processing: 666 resumes\n",
      "Starting processing: 667 resumes\n",
      "Starting processing: 668 resumes\n",
      "Starting processing: 669 resumes\n",
      "Starting processing: 670 resumes\n",
      "Starting processing: 671 resumes\n",
      "Starting processing: 672 resumes\n",
      "Starting processing: 673 resumes\n",
      "Starting processing: 674 resumes\n",
      "Starting processing: 675 resumes\n",
      "Starting processing: 676 resumes\n",
      "Starting processing: 677 resumes\n",
      "Starting processing: 678 resumes\n",
      "Starting processing: 679 resumes\n",
      "Starting processing: 680 resumes\n",
      "Starting processing: 681 resumes\n",
      "Starting processing: 682 resumes\n",
      "Starting processing: 683 resumes\n",
      "Starting processing: 684 resumes\n",
      "Starting processing: 685 resumes\n",
      "Starting processing: 686 resumes\n",
      "Starting processing: 687 resumes\n",
      "Starting processing: 688 resumes\n",
      "Starting processing: 689 resumes\n",
      "Starting processing: 690 resumes\n",
      "Starting processing: 691 resumes\n",
      "Starting processing: 692 resumes\n",
      "Starting processing: 693 resumes\n",
      "Starting processing: 694 resumes\n",
      "Starting processing: 695 resumes\n",
      "Starting processing: 696 resumes\n",
      "Starting processing: 697 resumes\n",
      "Starting processing: 698 resumes\n",
      "Starting processing: 699 resumes\n",
      "Starting processing: 700 resumes\n",
      "Starting processing: 701 resumes\n",
      "Starting processing: 702 resumes\n",
      "Starting processing: 703 resumes\n",
      "Starting processing: 704 resumes\n",
      "Starting processing: 705 resumes\n",
      "Starting processing: 706 resumes\n",
      "Starting processing: 707 resumes\n",
      "Starting processing: 708 resumes\n",
      "Starting processing: 709 resumes\n",
      "Starting processing: 710 resumes\n",
      "Starting processing: 711 resumes\n",
      "Starting processing: 712 resumes\n",
      "Starting processing: 713 resumes\n",
      "Starting processing: 714 resumes\n",
      "Starting processing: 715 resumes\n",
      "Starting processing: 716 resumes\n",
      "Starting processing: 717 resumes\n",
      "Starting processing: 718 resumes\n",
      "Starting processing: 719 resumes\n",
      "Starting processing: 720 resumes\n",
      "Starting processing: 721 resumes\n",
      "Starting processing: 722 resumes\n",
      "Starting processing: 723 resumes\n",
      "Starting processing: 724 resumes\n",
      "Starting processing: 725 resumes\n",
      "Starting processing: 726 resumes\n",
      "Starting processing: 727 resumes\n",
      "Starting processing: 728 resumes\n",
      "Starting processing: 729 resumes\n",
      "Starting processing: 730 resumes\n",
      "Starting processing: 731 resumes\n",
      "Starting processing: 732 resumes\n",
      "Starting processing: 733 resumes\n",
      "Starting processing: 734 resumes\n",
      "Starting processing: 735 resumes\n",
      "Starting processing: 736 resumes\n",
      "Starting processing: 737 resumes\n",
      "Starting processing: 738 resumes\n",
      "Starting processing: 739 resumes\n",
      "Starting processing: 740 resumes\n",
      "Starting processing: 741 resumes\n",
      "Starting processing: 742 resumes\n",
      "Starting processing: 743 resumes\n",
      "Starting processing: 744 resumes\n",
      "Starting processing: 745 resumes\n",
      "Starting processing: 746 resumes\n",
      "Starting processing: 747 resumes\n",
      "Starting processing: 748 resumes\n",
      "Starting processing: 749 resumes\n",
      "Starting processing: 750 resumes\n",
      "Starting processing: 751 resumes\n",
      "Starting processing: 752 resumes\n",
      "Starting processing: 753 resumes\n",
      "Starting processing: 754 resumes\n",
      "Starting processing: 755 resumes\n",
      "Starting processing: 756 resumes\n",
      "Starting processing: 757 resumes\n",
      "Starting processing: 758 resumes\n",
      "Starting processing: 759 resumes\n",
      "Starting processing: 760 resumes\n",
      "Starting processing: 761 resumes\n",
      "Starting processing: 762 resumes\n",
      "Starting processing: 763 resumes\n",
      "Starting processing: 764 resumes\n",
      "Starting processing: 765 resumes\n",
      "Starting processing: 766 resumes\n",
      "Starting processing: 767 resumes\n",
      "Starting processing: 768 resumes\n",
      "Starting processing: 769 resumes\n",
      "Starting processing: 770 resumes\n",
      "Starting processing: 771 resumes\n",
      "Starting processing: 772 resumes\n",
      "Starting processing: 773 resumes\n",
      "Starting processing: 774 resumes\n",
      "Starting processing: 775 resumes\n",
      "Starting processing: 776 resumes\n",
      "Starting processing: 777 resumes\n",
      "Starting processing: 778 resumes\n",
      "Starting processing: 779 resumes\n",
      "Starting processing: 780 resumes\n",
      "Starting processing: 781 resumes\n",
      "Starting processing: 782 resumes\n",
      "Starting processing: 783 resumes\n",
      "Starting processing: 784 resumes\n",
      "Starting processing: 785 resumes\n",
      "Starting processing: 786 resumes\n",
      "Starting processing: 787 resumes\n",
      "Starting processing: 788 resumes\n",
      "Starting processing: 789 resumes\n",
      "Starting processing: 790 resumes\n",
      "Starting processing: 791 resumes\n",
      "Starting processing: 792 resumes\n",
      "Starting processing: 793 resumes\n",
      "Starting processing: 794 resumes\n",
      "Starting processing: 795 resumes\n",
      "Starting processing: 796 resumes\n",
      "Starting processing: 797 resumes\n",
      "Starting processing: 798 resumes\n",
      "Starting processing: 799 resumes\n",
      "Starting processing: 800 resumes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing: 801 resumes\n",
      "Starting processing: 802 resumes\n",
      "Starting processing: 803 resumes\n",
      "Starting processing: 804 resumes\n",
      "Starting processing: 805 resumes\n",
      "Starting processing: 806 resumes\n",
      "Starting processing: 807 resumes\n",
      "Starting processing: 808 resumes\n",
      "Starting processing: 809 resumes\n",
      "Starting processing: 810 resumes\n",
      "Starting processing: 811 resumes\n",
      "Starting processing: 812 resumes\n",
      "Starting processing: 813 resumes\n",
      "Starting processing: 814 resumes\n",
      "Starting processing: 815 resumes\n",
      "Starting processing: 816 resumes\n",
      "Starting processing: 817 resumes\n",
      "Starting processing: 818 resumes\n",
      "Starting processing: 819 resumes\n",
      "Starting processing: 820 resumes\n",
      "Starting processing: 821 resumes\n",
      "Starting processing: 822 resumes\n",
      "Starting processing: 823 resumes\n",
      "Starting processing: 824 resumes\n",
      "Starting processing: 825 resumes\n",
      "Starting processing: 826 resumes\n",
      "Starting processing: 827 resumes\n",
      "Starting processing: 828 resumes\n",
      "Starting processing: 829 resumes\n",
      "Starting processing: 830 resumes\n",
      "Starting processing: 831 resumes\n",
      "Starting processing: 832 resumes\n",
      "Starting processing: 833 resumes\n",
      "Starting processing: 834 resumes\n",
      "Starting processing: 835 resumes\n",
      "Starting processing: 836 resumes\n",
      "Starting processing: 837 resumes\n",
      "Starting processing: 838 resumes\n",
      "Starting processing: 839 resumes\n",
      "Starting processing: 840 resumes\n",
      "Starting processing: 841 resumes\n",
      "Starting processing: 842 resumes\n",
      "Starting processing: 843 resumes\n",
      "Starting processing: 844 resumes\n",
      "Starting processing: 845 resumes\n",
      "Starting processing: 846 resumes\n",
      "Starting processing: 847 resumes\n",
      "Starting processing: 848 resumes\n",
      "Starting processing: 849 resumes\n",
      "Starting processing: 850 resumes\n",
      "Starting processing: 851 resumes\n",
      "Starting processing: 852 resumes\n",
      "Starting processing: 853 resumes\n",
      "Starting processing: 854 resumes\n",
      "Starting processing: 855 resumes\n",
      "Starting processing: 856 resumes\n",
      "Starting processing: 857 resumes\n",
      "Starting processing: 858 resumes\n",
      "Starting processing: 859 resumes\n",
      "Starting processing: 860 resumes\n",
      "Starting processing: 861 resumes\n",
      "Starting processing: 862 resumes\n",
      "Starting processing: 863 resumes\n",
      "Starting processing: 864 resumes\n",
      "Starting processing: 865 resumes\n",
      "Starting processing: 866 resumes\n",
      "Starting processing: 867 resumes\n",
      "Starting processing: 868 resumes\n",
      "Starting processing: 869 resumes\n",
      "Starting processing: 870 resumes\n",
      "Starting processing: 871 resumes\n",
      "Starting processing: 872 resumes\n",
      "Starting processing: 873 resumes\n",
      "Starting processing: 874 resumes\n",
      "Starting processing: 875 resumes\n",
      "Starting processing: 876 resumes\n",
      "Starting processing: 877 resumes\n",
      "Starting processing: 878 resumes\n",
      "Starting processing: 879 resumes\n",
      "Starting processing: 880 resumes\n",
      "Starting processing: 881 resumes\n",
      "Starting processing: 882 resumes\n",
      "Starting processing: 883 resumes\n",
      "Starting processing: 884 resumes\n",
      "Starting processing: 885 resumes\n",
      "Starting processing: 886 resumes\n",
      "Starting processing: 887 resumes\n",
      "Starting processing: 888 resumes\n",
      "Starting processing: 889 resumes\n",
      "Starting processing: 890 resumes\n",
      "Starting processing: 891 resumes\n",
      "Starting processing: 892 resumes\n",
      "Starting processing: 893 resumes\n",
      "Starting processing: 894 resumes\n",
      "Starting processing: 895 resumes\n",
      "Starting processing: 896 resumes\n",
      "Starting processing: 897 resumes\n",
      "Starting processing: 898 resumes\n",
      "Starting processing: 899 resumes\n",
      "Starting processing: 900 resumes\n",
      "Starting processing: 901 resumes\n",
      "Starting processing: 902 resumes\n",
      "Starting processing: 903 resumes\n",
      "Starting processing: 904 resumes\n",
      "Starting processing: 905 resumes\n",
      "Starting processing: 906 resumes\n",
      "Starting processing: 907 resumes\n",
      "Starting processing: 908 resumes\n",
      "Starting processing: 909 resumes\n",
      "Starting processing: 910 resumes\n",
      "Starting processing: 911 resumes\n",
      "Starting processing: 912 resumes\n",
      "Starting processing: 913 resumes\n",
      "Starting processing: 914 resumes\n",
      "Starting processing: 915 resumes\n",
      "Starting processing: 916 resumes\n",
      "Starting processing: 917 resumes\n",
      "Starting processing: 918 resumes\n",
      "Starting processing: 919 resumes\n",
      "Starting processing: 920 resumes\n",
      "Starting processing: 921 resumes\n",
      "Starting processing: 922 resumes\n",
      "Starting processing: 923 resumes\n",
      "Starting processing: 924 resumes\n",
      "Starting processing: 925 resumes\n",
      "Starting processing: 926 resumes\n",
      "Starting processing: 927 resumes\n",
      "Starting processing: 928 resumes\n",
      "Starting processing: 929 resumes\n",
      "Starting processing: 930 resumes\n",
      "Starting processing: 931 resumes\n",
      "Starting processing: 932 resumes\n",
      "Starting processing: 933 resumes\n",
      "Starting processing: 934 resumes\n",
      "Starting processing: 935 resumes\n",
      "Starting processing: 936 resumes\n",
      "Starting processing: 937 resumes\n",
      "Starting processing: 938 resumes\n",
      "Starting processing: 939 resumes\n",
      "Starting processing: 940 resumes\n",
      "Starting processing: 941 resumes\n",
      "Starting processing: 942 resumes\n",
      "Starting processing: 943 resumes\n",
      "Starting processing: 944 resumes\n",
      "Starting processing: 945 resumes\n",
      "Starting processing: 946 resumes\n",
      "Starting processing: 947 resumes\n",
      "Starting processing: 948 resumes\n",
      "Starting processing: 949 resumes\n",
      "Starting processing: 950 resumes\n",
      "Starting processing: 951 resumes\n",
      "Starting processing: 952 resumes\n",
      "Starting processing: 953 resumes\n",
      "Starting processing: 954 resumes\n",
      "Starting processing: 955 resumes\n",
      "Starting processing: 956 resumes\n",
      "Starting processing: 957 resumes\n",
      "Starting processing: 958 resumes\n",
      "Starting processing: 959 resumes\n",
      "Starting processing: 960 resumes\n",
      "Starting processing: 961 resumes\n",
      "Starting processing: 962 resumes\n",
      "Starting processing: 963 resumes\n",
      "Starting processing: 964 resumes\n",
      "Starting processing: 965 resumes\n",
      "Starting processing: 966 resumes\n",
      "Starting processing: 967 resumes\n",
      "Starting processing: 968 resumes\n",
      "Starting processing: 969 resumes\n",
      "Starting processing: 970 resumes\n",
      "Starting processing: 971 resumes\n",
      "Starting processing: 972 resumes\n",
      "Starting processing: 973 resumes\n",
      "Starting processing: 974 resumes\n",
      "Starting processing: 975 resumes\n",
      "Starting processing: 976 resumes\n",
      "Starting processing: 977 resumes\n",
      "Starting processing: 978 resumes\n",
      "Starting processing: 979 resumes\n",
      "Starting processing: 980 resumes\n",
      "Starting processing: 981 resumes\n",
      "Starting processing: 982 resumes\n",
      "Starting processing: 983 resumes\n",
      "Starting processing: 984 resumes\n",
      "Starting processing: 985 resumes\n",
      "Starting processing: 986 resumes\n",
      "Starting processing: 987 resumes\n",
      "Starting processing: 988 resumes\n",
      "Starting processing: 989 resumes\n",
      "Starting processing: 990 resumes\n",
      "Starting processing: 991 resumes\n",
      "Starting processing: 992 resumes\n",
      "Starting processing: 993 resumes\n",
      "Starting processing: 994 resumes\n",
      "Starting processing: 995 resumes\n",
      "Starting processing: 996 resumes\n",
      "Starting processing: 997 resumes\n",
      "Starting processing: 998 resumes\n",
      "Starting processing: 999 resumes\n",
      "Starting processing: 1000 resumes\n",
      "Starting processing: 1001 resumes\n",
      "Starting processing: 1002 resumes\n",
      "Starting processing: 1003 resumes\n",
      "Starting processing: 1004 resumes\n",
      "Starting processing: 1005 resumes\n",
      "Starting processing: 1006 resumes\n",
      "Starting processing: 1007 resumes\n",
      "Starting processing: 1008 resumes\n",
      "Starting processing: 1009 resumes\n",
      "Starting processing: 1010 resumes\n",
      "Starting processing: 1011 resumes\n",
      "Starting processing: 1012 resumes\n",
      "Starting processing: 1013 resumes\n",
      "Starting processing: 1014 resumes\n",
      "Starting processing: 1015 resumes\n",
      "Starting processing: 1016 resumes\n",
      "Starting processing: 1017 resumes\n",
      "Starting processing: 1018 resumes\n",
      "Starting processing: 1019 resumes\n",
      "Starting processing: 1020 resumes\n",
      "Starting processing: 1021 resumes\n",
      "Starting processing: 1022 resumes\n",
      "Starting processing: 1023 resumes\n",
      "Starting processing: 1024 resumes\n",
      "Starting processing: 1025 resumes\n",
      "Starting processing: 1026 resumes\n",
      "Starting processing: 1027 resumes\n",
      "Starting processing: 1028 resumes\n",
      "Starting processing: 1029 resumes\n",
      "Starting processing: 1030 resumes\n",
      "Starting processing: 1031 resumes\n",
      "Starting processing: 1032 resumes\n",
      "Starting processing: 1033 resumes\n",
      "Starting processing: 1034 resumes\n",
      "Starting processing: 1035 resumes\n",
      "Starting processing: 1036 resumes\n",
      "Starting processing: 1037 resumes\n",
      "Starting processing: 1038 resumes\n",
      "Starting processing: 1039 resumes\n",
      "Starting processing: 1040 resumes\n",
      "Starting processing: 1041 resumes\n",
      "Starting processing: 1042 resumes\n",
      "Starting processing: 1043 resumes\n",
      "Starting processing: 1044 resumes\n",
      "Starting processing: 1045 resumes\n",
      "Starting processing: 1046 resumes\n",
      "Starting processing: 1047 resumes\n",
      "Starting processing: 1048 resumes\n",
      "Starting processing: 1049 resumes\n",
      "Starting processing: 1050 resumes\n",
      "Starting processing: 1051 resumes\n",
      "Starting processing: 1052 resumes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing: 1053 resumes\n",
      "Starting processing: 1054 resumes\n",
      "Starting processing: 1055 resumes\n",
      "Starting processing: 1056 resumes\n",
      "Starting processing: 1057 resumes\n",
      "Starting processing: 1058 resumes\n",
      "Starting processing: 1059 resumes\n",
      "Starting processing: 1060 resumes\n",
      "Starting processing: 1061 resumes\n",
      "Starting processing: 1062 resumes\n",
      "Starting processing: 1063 resumes\n",
      "Starting processing: 1064 resumes\n",
      "Starting processing: 1065 resumes\n",
      "Starting processing: 1066 resumes\n",
      "Starting processing: 1067 resumes\n",
      "Starting processing: 1068 resumes\n",
      "Starting processing: 1069 resumes\n",
      "Starting processing: 1070 resumes\n",
      "Starting processing: 1071 resumes\n",
      "Starting processing: 1072 resumes\n",
      "Starting processing: 1073 resumes\n",
      "Starting processing: 1074 resumes\n",
      "Starting processing: 1075 resumes\n",
      "Starting processing: 1076 resumes\n",
      "Starting processing: 1077 resumes\n",
      "Starting processing: 1078 resumes\n",
      "Starting processing: 1079 resumes\n",
      "Starting processing: 1080 resumes\n",
      "Starting processing: 1081 resumes\n",
      "Starting processing: 1082 resumes\n",
      "Starting processing: 1083 resumes\n",
      "Starting processing: 1084 resumes\n",
      "Starting processing: 1085 resumes\n",
      "Starting processing: 1086 resumes\n",
      "Starting processing: 1087 resumes\n",
      "Starting processing: 1088 resumes\n",
      "Starting processing: 1089 resumes\n",
      "Starting processing: 1090 resumes\n",
      "Starting processing: 1091 resumes\n",
      "Starting processing: 1092 resumes\n",
      "Starting processing: 1093 resumes\n",
      "Starting processing: 1094 resumes\n",
      "Starting processing: 1095 resumes\n",
      "Starting processing: 1096 resumes\n",
      "Starting processing: 1097 resumes\n",
      "Starting processing: 1098 resumes\n",
      "Starting processing: 1099 resumes\n",
      "Starting processing: 1100 resumes\n",
      "Starting processing: 1101 resumes\n",
      "Starting processing: 1102 resumes\n",
      "Starting processing: 1103 resumes\n",
      "Starting processing: 1104 resumes\n",
      "Starting processing: 1105 resumes\n",
      "Starting processing: 1106 resumes\n",
      "Starting processing: 1107 resumes\n",
      "Starting processing: 1108 resumes\n",
      "Starting processing: 1109 resumes\n",
      "Starting processing: 1110 resumes\n",
      "Starting processing: 1111 resumes\n",
      "Starting processing: 1112 resumes\n",
      "Starting processing: 1113 resumes\n",
      "Starting processing: 1114 resumes\n",
      "Starting processing: 1115 resumes\n",
      "Starting processing: 1116 resumes\n",
      "Starting processing: 1117 resumes\n",
      "Starting processing: 1118 resumes\n",
      "Starting processing: 1119 resumes\n",
      "Starting processing: 1120 resumes\n",
      "Starting processing: 1121 resumes\n",
      "Starting processing: 1122 resumes\n",
      "Starting processing: 1123 resumes\n",
      "Starting processing: 1124 resumes\n",
      "Starting processing: 1125 resumes\n",
      "Starting processing: 1126 resumes\n",
      "Starting processing: 1127 resumes\n",
      "Starting processing: 1128 resumes\n",
      "Starting processing: 1129 resumes\n",
      "Starting processing: 1130 resumes\n",
      "Starting processing: 1131 resumes\n",
      "Starting processing: 1132 resumes\n",
      "Starting processing: 1133 resumes\n",
      "Starting processing: 1134 resumes\n",
      "Starting processing: 1135 resumes\n",
      "Starting processing: 1136 resumes\n",
      "Starting processing: 1137 resumes\n",
      "Starting processing: 1138 resumes\n",
      "Starting processing: 1139 resumes\n",
      "Starting processing: 1140 resumes\n",
      "Starting processing: 1141 resumes\n",
      "Starting processing: 1142 resumes\n",
      "Starting processing: 1143 resumes\n",
      "Starting processing: 1144 resumes\n",
      "Starting processing: 1145 resumes\n",
      "Starting processing: 1146 resumes\n",
      "Starting processing: 1147 resumes\n",
      "Starting processing: 1148 resumes\n",
      "Starting processing: 1149 resumes\n",
      "Starting processing: 1150 resumes\n",
      "Starting processing: 1151 resumes\n",
      "Starting processing: 1152 resumes\n",
      "Starting processing: 1153 resumes\n",
      "Starting processing: 1154 resumes\n",
      "Starting processing: 1155 resumes\n",
      "Starting processing: 1156 resumes\n",
      "Starting processing: 1157 resumes\n",
      "Starting processing: 1158 resumes\n",
      "Starting processing: 1159 resumes\n",
      "Starting processing: 1160 resumes\n",
      "Starting processing: 1161 resumes\n",
      "Starting processing: 1162 resumes\n",
      "Starting processing: 1163 resumes\n",
      "Starting processing: 1164 resumes\n",
      "Starting processing: 1165 resumes\n",
      "Starting processing: 1166 resumes\n",
      "Starting processing: 1167 resumes\n",
      "Starting processing: 1168 resumes\n",
      "Starting processing: 1169 resumes\n",
      "Starting processing: 1170 resumes\n",
      "Starting processing: 1171 resumes\n",
      "Starting processing: 1172 resumes\n",
      "Starting processing: 1173 resumes\n",
      "Starting processing: 1174 resumes\n",
      "Starting processing: 1175 resumes\n",
      "Starting processing: 1176 resumes\n",
      "Starting processing: 1177 resumes\n",
      "Starting processing: 1178 resumes\n",
      "Starting processing: 1179 resumes\n",
      "Starting processing: 1180 resumes\n",
      "Starting processing: 1181 resumes\n",
      "Starting processing: 1182 resumes\n",
      "Starting processing: 1183 resumes\n",
      "Starting processing: 1184 resumes\n",
      "Starting processing: 1185 resumes\n",
      "Starting processing: 1186 resumes\n",
      "Starting processing: 1187 resumes\n",
      "Starting processing: 1188 resumes\n",
      "Starting processing: 1189 resumes\n",
      "Starting processing: 1190 resumes\n",
      "Starting processing: 1191 resumes\n",
      "Starting processing: 1192 resumes\n",
      "Starting processing: 1193 resumes\n",
      "Starting processing: 1194 resumes\n",
      "Starting processing: 1195 resumes\n",
      "Starting processing: 1196 resumes\n",
      "Starting processing: 1197 resumes\n",
      "Starting processing: 1198 resumes\n",
      "Starting processing: 1199 resumes\n",
      "Starting processing: 1200 resumes\n",
      "Starting processing: 1201 resumes\n",
      "Starting processing: 1202 resumes\n",
      "Starting processing: 1203 resumes\n",
      "Starting processing: 1204 resumes\n",
      "Starting processing: 1205 resumes\n",
      "Starting processing: 1206 resumes\n",
      "Starting processing: 1207 resumes\n",
      "Starting processing: 1208 resumes\n",
      "Starting processing: 1209 resumes\n",
      "Starting processing: 1210 resumes\n",
      "Starting processing: 1211 resumes\n",
      "Starting processing: 1212 resumes\n",
      "Starting processing: 1213 resumes\n",
      "Starting processing: 1214 resumes\n",
      "Starting processing: 1215 resumes\n",
      "Starting processing: 1216 resumes\n",
      "Starting processing: 1217 resumes\n",
      "Starting processing: 1218 resumes\n",
      "Starting processing: 1219 resumes\n",
      "Starting processing: 1220 resumes\n",
      "Starting processing: 1221 resumes\n",
      "Starting processing: 1222 resumes\n",
      "Starting processing: 1223 resumes\n",
      "Starting processing: 1224 resumes\n",
      "Starting processing: 1225 resumes\n",
      "Starting processing: 1226 resumes\n",
      "Starting processing: 1227 resumes\n",
      "Starting processing: 1228 resumes\n",
      "Starting processing: 1229 resumes\n",
      "Starting processing: 1230 resumes\n",
      "Starting processing: 1231 resumes\n",
      "Starting processing: 1232 resumes\n",
      "Starting processing: 1233 resumes\n",
      "Starting processing: 1234 resumes\n",
      "Starting processing: 1235 resumes\n",
      "Starting processing: 1236 resumes\n",
      "Starting processing: 1237 resumes\n",
      "Starting processing: 1238 resumes\n",
      "Starting processing: 1239 resumes\n",
      "Starting processing: 1240 resumes\n",
      "Starting processing: 1241 resumes\n",
      "Starting processing: 1242 resumes\n",
      "Starting processing: 1243 resumes\n",
      "Starting processing: 1244 resumes\n",
      "Starting processing: 1245 resumes\n",
      "Starting processing: 1246 resumes\n",
      "Starting processing: 1247 resumes\n",
      "Starting processing: 1248 resumes\n",
      "Starting processing: 1249 resumes\n",
      "Starting processing: 1250 resumes\n",
      "Starting processing: 1251 resumes\n",
      "Starting processing: 1252 resumes\n",
      "Starting processing: 1253 resumes\n",
      "Starting processing: 1254 resumes\n",
      "Starting processing: 1255 resumes\n",
      "Starting processing: 1256 resumes\n",
      "Starting processing: 1257 resumes\n",
      "Starting processing: 1258 resumes\n",
      "Starting processing: 1259 resumes\n",
      "Starting processing: 1260 resumes\n",
      "Starting processing: 1261 resumes\n",
      "Starting processing: 1262 resumes\n",
      "Starting processing: 1263 resumes\n",
      "Starting processing: 1264 resumes\n",
      "Starting processing: 1265 resumes\n",
      "Starting processing: 1266 resumes\n",
      "Starting processing: 1267 resumes\n",
      "Starting processing: 1268 resumes\n",
      "Starting processing: 1269 resumes\n",
      "Starting processing: 1270 resumes\n",
      "Starting processing: 1271 resumes\n",
      "Starting processing: 1272 resumes\n",
      "Starting processing: 1273 resumes\n",
      "Starting processing: 1274 resumes\n",
      "Starting processing: 1275 resumes\n",
      "Starting processing: 1276 resumes\n",
      "Starting processing: 1277 resumes\n",
      "Starting processing: 1278 resumes\n",
      "Starting processing: 1279 resumes\n",
      "Starting processing: 1280 resumes\n",
      "Starting processing: 1281 resumes\n",
      "Starting processing: 1282 resumes\n",
      "Starting processing: 1283 resumes\n",
      "Starting processing: 1284 resumes\n",
      "Starting processing: 1285 resumes\n",
      "Starting processing: 1286 resumes\n",
      "Starting processing: 1287 resumes\n",
      "Starting processing: 1288 resumes\n",
      "Starting processing: 1289 resumes\n",
      "Starting processing: 1290 resumes\n",
      "Starting processing: 1291 resumes\n",
      "Starting processing: 1292 resumes\n",
      "Starting processing: 1293 resumes\n",
      "Starting processing: 1294 resumes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing: 1295 resumes\n",
      "Starting processing: 1296 resumes\n",
      "Starting processing: 1297 resumes\n",
      "Starting processing: 1298 resumes\n",
      "Starting processing: 1299 resumes\n",
      "Starting processing: 1300 resumes\n",
      "Starting processing: 1301 resumes\n",
      "Starting processing: 1302 resumes\n",
      "Starting processing: 1303 resumes\n",
      "Starting processing: 1304 resumes\n",
      "Starting processing: 1305 resumes\n",
      "Starting processing: 1306 resumes\n",
      "Starting processing: 1307 resumes\n",
      "Starting processing: 1308 resumes\n",
      "Starting processing: 1309 resumes\n",
      "Starting processing: 1310 resumes\n",
      "Starting processing: 1311 resumes\n",
      "Starting processing: 1312 resumes\n",
      "Starting processing: 1313 resumes\n",
      "Starting processing: 1314 resumes\n",
      "Starting processing: 1315 resumes\n",
      "Starting processing: 1316 resumes\n",
      "Starting processing: 1317 resumes\n",
      "Starting processing: 1318 resumes\n",
      "Starting processing: 1319 resumes\n",
      "Starting processing: 1320 resumes\n",
      "Starting processing: 1321 resumes\n",
      "Starting processing: 1322 resumes\n",
      "Starting processing: 1323 resumes\n",
      "Starting processing: 1324 resumes\n",
      "Starting processing: 1325 resumes\n",
      "Starting processing: 1326 resumes\n",
      "Starting processing: 1327 resumes\n",
      "Starting processing: 1328 resumes\n",
      "Starting processing: 1329 resumes\n",
      "Starting processing: 1330 resumes\n",
      "Starting processing: 1331 resumes\n",
      "Starting processing: 1332 resumes\n",
      "Starting processing: 1333 resumes\n",
      "Starting processing: 1334 resumes\n",
      "Starting processing: 1335 resumes\n",
      "Starting processing: 1336 resumes\n",
      "Starting processing: 1337 resumes\n",
      "Starting processing: 1338 resumes\n",
      "Starting processing: 1339 resumes\n",
      "Starting processing: 1340 resumes\n",
      "Starting processing: 1341 resumes\n",
      "Starting processing: 1342 resumes\n",
      "Starting processing: 1343 resumes\n",
      "Starting processing: 1344 resumes\n",
      "Starting processing: 1345 resumes\n",
      "Starting processing: 1346 resumes\n",
      "Starting processing: 1347 resumes\n",
      "Starting processing: 1348 resumes\n",
      "Starting processing: 1349 resumes\n",
      "Starting processing: 1350 resumes\n",
      "Starting processing: 1351 resumes\n",
      "Starting processing: 1352 resumes\n",
      "Starting processing: 1353 resumes\n",
      "Starting processing: 1354 resumes\n",
      "Starting processing: 1355 resumes\n",
      "Starting processing: 1356 resumes\n",
      "Starting processing: 1357 resumes\n",
      "Starting processing: 1358 resumes\n",
      "Starting processing: 1359 resumes\n",
      "Starting processing: 1360 resumes\n",
      "Starting processing: 1361 resumes\n",
      "Starting processing: 1362 resumes\n",
      "Starting processing: 1363 resumes\n",
      "Starting processing: 1364 resumes\n",
      "Starting processing: 1365 resumes\n",
      "Starting processing: 1366 resumes\n",
      "Starting processing: 1367 resumes\n",
      "Starting processing: 1368 resumes\n",
      "Starting processing: 1369 resumes\n",
      "Starting processing: 1370 resumes\n",
      "Starting processing: 1371 resumes\n",
      "Starting processing: 1372 resumes\n",
      "Starting processing: 1373 resumes\n",
      "Starting processing: 1374 resumes\n",
      "Starting processing: 1375 resumes\n",
      "Starting processing: 1376 resumes\n",
      "Starting processing: 1377 resumes\n",
      "Starting processing: 1378 resumes\n",
      "Starting processing: 1379 resumes\n",
      "Starting processing: 1380 resumes\n",
      "Starting processing: 1381 resumes\n",
      "Starting processing: 1382 resumes\n",
      "Starting processing: 1383 resumes\n",
      "Starting processing: 1384 resumes\n",
      "Starting processing: 1385 resumes\n",
      "Starting processing: 1386 resumes\n",
      "Starting processing: 1387 resumes\n",
      "Starting processing: 1388 resumes\n",
      "Starting processing: 1389 resumes\n",
      "Starting processing: 1390 resumes\n",
      "Starting processing: 1391 resumes\n",
      "Starting processing: 1392 resumes\n",
      "Starting processing: 1393 resumes\n",
      "Starting processing: 1394 resumes\n",
      "Starting processing: 1395 resumes\n",
      "Starting processing: 1396 resumes\n",
      "Starting processing: 1397 resumes\n",
      "Starting processing: 1398 resumes\n",
      "Starting processing: 1399 resumes\n",
      "Starting processing: 1400 resumes\n",
      "Starting processing: 1401 resumes\n",
      "Starting processing: 1402 resumes\n",
      "Starting processing: 1403 resumes\n",
      "Starting processing: 1404 resumes\n",
      "Starting processing: 1405 resumes\n",
      "Starting processing: 1406 resumes\n",
      "Starting processing: 1407 resumes\n",
      "Starting processing: 1408 resumes\n",
      "Starting processing: 1409 resumes\n",
      "Starting processing: 1410 resumes\n",
      "Starting processing: 1411 resumes\n",
      "Starting processing: 1412 resumes\n",
      "Starting processing: 1413 resumes\n",
      "Starting processing: 1414 resumes\n",
      "Starting processing: 1415 resumes\n",
      "Starting processing: 1416 resumes\n",
      "Starting processing: 1417 resumes\n",
      "Starting processing: 1418 resumes\n",
      "Starting processing: 1419 resumes\n",
      "Starting processing: 1420 resumes\n",
      "Starting processing: 1421 resumes\n",
      "Starting processing: 1422 resumes\n",
      "Starting processing: 1423 resumes\n",
      "Starting processing: 1424 resumes\n",
      "Starting processing: 1425 resumes\n",
      "Starting processing: 1426 resumes\n",
      "Starting processing: 1427 resumes\n",
      "Starting processing: 1428 resumes\n",
      "Starting processing: 1429 resumes\n",
      "Starting processing: 1430 resumes\n",
      "Starting processing: 1431 resumes\n",
      "Starting processing: 1432 resumes\n",
      "Starting processing: 1433 resumes\n",
      "Starting processing: 1434 resumes\n",
      "Starting processing: 1435 resumes\n",
      "Starting processing: 1436 resumes\n",
      "Starting processing: 1437 resumes\n",
      "Starting processing: 1438 resumes\n",
      "Starting processing: 1439 resumes\n",
      "Starting processing: 1440 resumes\n",
      "Starting processing: 1441 resumes\n",
      "Starting processing: 1442 resumes\n",
      "Starting processing: 1443 resumes\n",
      "Starting processing: 1444 resumes\n",
      "Starting processing: 1445 resumes\n",
      "Starting processing: 1446 resumes\n",
      "Starting processing: 1447 resumes\n",
      "Starting processing: 1448 resumes\n",
      "Starting processing: 1449 resumes\n",
      "Starting processing: 1450 resumes\n",
      "Starting processing: 1451 resumes\n",
      "Starting processing: 1452 resumes\n",
      "Starting processing: 1453 resumes\n",
      "Starting processing: 1454 resumes\n",
      "Starting processing: 1455 resumes\n",
      "Starting processing: 1456 resumes\n",
      "Starting processing: 1457 resumes\n",
      "Starting processing: 1458 resumes\n",
      "Starting processing: 1459 resumes\n",
      "Starting processing: 1460 resumes\n",
      "Starting processing: 1461 resumes\n",
      "Starting processing: 1462 resumes\n",
      "Starting processing: 1463 resumes\n",
      "Starting processing: 1464 resumes\n",
      "Starting processing: 1465 resumes\n",
      "Starting processing: 1466 resumes\n",
      "Starting processing: 1467 resumes\n",
      "Starting processing: 1468 resumes\n",
      "Starting processing: 1469 resumes\n",
      "Starting processing: 1470 resumes\n",
      "Starting processing: 1471 resumes\n",
      "Starting processing: 1472 resumes\n",
      "Starting processing: 1473 resumes\n",
      "Starting processing: 1474 resumes\n",
      "Starting processing: 1475 resumes\n",
      "Starting processing: 1476 resumes\n",
      "Starting processing: 1477 resumes\n",
      "Starting processing: 1478 resumes\n",
      "Starting processing: 1479 resumes\n",
      "Starting processing: 1480 resumes\n",
      "Starting processing: 1481 resumes\n",
      "Starting processing: 1482 resumes\n",
      "Starting processing: 1483 resumes\n",
      "Starting processing: 1484 resumes\n",
      "Starting processing: 1485 resumes\n",
      "Starting processing: 1486 resumes\n",
      "Starting processing: 1487 resumes\n",
      "Starting processing: 1488 resumes\n",
      "Starting processing: 1489 resumes\n",
      "Starting processing: 1490 resumes\n",
      "Starting processing: 1491 resumes\n",
      "Starting processing: 1492 resumes\n",
      "Starting processing: 1493 resumes\n",
      "Starting processing: 1494 resumes\n",
      "Starting processing: 1495 resumes\n",
      "Starting processing: 1496 resumes\n",
      "Starting processing: 1497 resumes\n",
      "Starting processing: 1498 resumes\n",
      "Starting processing: 1499 resumes\n",
      "Starting processing: 1500 resumes\n",
      "Starting processing: 1501 resumes\n",
      "Starting processing: 1502 resumes\n",
      "Starting processing: 1503 resumes\n",
      "Starting processing: 1504 resumes\n",
      "Starting processing: 1505 resumes\n",
      "Starting processing: 1506 resumes\n",
      "Starting processing: 1507 resumes\n",
      "Starting processing: 1508 resumes\n",
      "Starting processing: 1509 resumes\n",
      "Starting processing: 1510 resumes\n",
      "Starting processing: 1511 resumes\n",
      "Starting processing: 1512 resumes\n",
      "Starting processing: 1513 resumes\n",
      "Starting processing: 1514 resumes\n",
      "Starting processing: 1515 resumes\n",
      "Starting processing: 1516 resumes\n",
      "Starting processing: 1517 resumes\n",
      "Starting processing: 1518 resumes\n",
      "Starting processing: 1519 resumes\n",
      "Starting processing: 1520 resumes\n",
      "Starting processing: 1521 resumes\n",
      "Starting processing: 1522 resumes\n",
      "Starting processing: 1523 resumes\n",
      "Starting processing: 1524 resumes\n",
      "Starting processing: 1525 resumes\n",
      "Starting processing: 1526 resumes\n",
      "Starting processing: 1527 resumes\n",
      "Starting processing: 1528 resumes\n",
      "Starting processing: 1529 resumes\n",
      "Starting processing: 1530 resumes\n",
      "Starting processing: 1531 resumes\n",
      "Starting processing: 1532 resumes\n",
      "Starting processing: 1533 resumes\n",
      "Starting processing: 1534 resumes\n",
      "Starting processing: 1535 resumes\n",
      "Starting processing: 1536 resumes\n",
      "Starting processing: 1537 resumes\n",
      "Starting processing: 1538 resumes\n",
      "Starting processing: 1539 resumes\n",
      "Starting processing: 1540 resumes\n",
      "Starting processing: 1541 resumes\n",
      "Starting processing: 1542 resumes\n",
      "Starting processing: 1543 resumes\n",
      "Starting processing: 1544 resumes\n",
      "Starting processing: 1545 resumes\n",
      "Starting processing: 1546 resumes\n",
      "Starting processing: 1547 resumes\n",
      "Starting processing: 1548 resumes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing: 1549 resumes\n",
      "Starting processing: 1550 resumes\n",
      "Starting processing: 1551 resumes\n",
      "Starting processing: 1552 resumes\n",
      "Starting processing: 1553 resumes\n",
      "Starting processing: 1554 resumes\n",
      "Starting processing: 1555 resumes\n",
      "Starting processing: 1556 resumes\n",
      "Starting processing: 1557 resumes\n",
      "Starting processing: 1558 resumes\n",
      "Starting processing: 1559 resumes\n",
      "Starting processing: 1560 resumes\n",
      "Starting processing: 1561 resumes\n",
      "Starting processing: 1562 resumes\n",
      "Starting processing: 1563 resumes\n",
      "Starting processing: 1564 resumes\n",
      "Starting processing: 1565 resumes\n",
      "Starting processing: 1566 resumes\n",
      "Starting processing: 1567 resumes\n",
      "Starting processing: 1568 resumes\n",
      "Starting processing: 1569 resumes\n",
      "Starting processing: 1570 resumes\n",
      "Starting processing: 1571 resumes\n",
      "Starting processing: 1572 resumes\n",
      "Starting processing: 1573 resumes\n",
      "Starting processing: 1574 resumes\n",
      "Starting processing: 1575 resumes\n",
      "Starting processing: 1576 resumes\n",
      "Starting processing: 1577 resumes\n",
      "Starting processing: 1578 resumes\n",
      "Starting processing: 1579 resumes\n",
      "Starting processing: 1580 resumes\n",
      "Starting processing: 1581 resumes\n",
      "Starting processing: 1582 resumes\n",
      "Starting processing: 1583 resumes\n",
      "Starting processing: 1584 resumes\n",
      "Starting processing: 1585 resumes\n",
      "Starting processing: 1586 resumes\n",
      "Starting processing: 1587 resumes\n",
      "Starting processing: 1588 resumes\n",
      "Starting processing: 1589 resumes\n",
      "Starting processing: 1590 resumes\n",
      "Starting processing: 1591 resumes\n",
      "Starting processing: 1592 resumes\n",
      "Starting processing: 1593 resumes\n",
      "Starting processing: 1594 resumes\n",
      "Starting processing: 1595 resumes\n",
      "Starting processing: 1596 resumes\n",
      "Starting processing: 1597 resumes\n",
      "Starting processing: 1598 resumes\n",
      "Starting processing: 1599 resumes\n",
      "Starting processing: 1600 resumes\n",
      "Starting processing: 1601 resumes\n",
      "Starting processing: 1602 resumes\n",
      "Starting processing: 1603 resumes\n",
      "Starting processing: 1604 resumes\n",
      "Starting processing: 1605 resumes\n",
      "Starting processing: 1606 resumes\n",
      "Starting processing: 1607 resumes\n",
      "Starting processing: 1608 resumes\n",
      "Starting processing: 1609 resumes\n",
      "Starting processing: 1610 resumes\n",
      "Starting processing: 1611 resumes\n",
      "Starting processing: 1612 resumes\n",
      "Starting processing: 1613 resumes\n",
      "Starting processing: 1614 resumes\n",
      "Starting processing: 1615 resumes\n",
      "Starting processing: 1616 resumes\n",
      "Starting processing: 1617 resumes\n",
      "Starting processing: 1618 resumes\n",
      "Starting processing: 1619 resumes\n",
      "Starting processing: 1620 resumes\n",
      "Starting processing: 1621 resumes\n",
      "Starting processing: 1622 resumes\n",
      "Starting processing: 1623 resumes\n",
      "Starting processing: 1624 resumes\n",
      "Starting processing: 1625 resumes\n",
      "Starting processing: 1626 resumes\n",
      "Starting processing: 1627 resumes\n",
      "Starting processing: 1628 resumes\n",
      "Starting processing: 1629 resumes\n",
      "Starting processing: 1630 resumes\n",
      "Starting processing: 1631 resumes\n",
      "Starting processing: 1632 resumes\n",
      "Starting processing: 1633 resumes\n",
      "Starting processing: 1634 resumes\n"
     ]
    }
   ],
   "source": [
    "read_raw_xml_and_extract_work_years()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_text_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xml_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "sys.setrecursionlimit(20000)\n",
    "\n",
    "# pickle.dump(train_text_set, open( \"data/train_2.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_xml_set, open( \"data/train_4_xml.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
